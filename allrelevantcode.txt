using System;
using System.IO;
using System.Security.Cryptography;
using Parquet.Meta.Proto;

namespace Parquet.Encryption {
    internal class AES_GCM_CTR_V1_Encryption : AES_GCM_V1_Encryption {
        private const int NonceLength = 12;

        public AES_GCM_CTR_V1_Encryption() {
        }

        protected override byte[] Decrypt(
            ThriftCompactProtocolReader reader,
            Meta.ParquetModules module,
            short? rowGroupOrdinal = null,
            short? columnOrdinal = null,
            short? pageOrdinal = null
        ) {
            // Data/Dictionary page bodies use CTR; everything else falls back to base (GCM)
            if(module == Meta.ParquetModules.Data_Page || module == Meta.ParquetModules.Dictionary_Page) {
                // Spec framing: length(4 LE) | nonce(12) | ciphertext
                byte[] lenBytes = ReadExactlyOrInvalid(reader, 4, "CTR length").EnsureLittleEndian();
                int totalLength = BitConverter.ToInt32(lenBytes, 0);

                const int NonceLen = 12;
                if(totalLength < NonceLen)
                    throw new InvalidDataException($"Encrypted CTR buffer too small ({totalLength} bytes).");

                byte[] nonce = ReadExactlyOrInvalid(reader, NonceLen, "CTR nonce");
                int ctLen = totalLength - NonceLen;
                if(ctLen < 0)
                    throw new InvalidDataException("Invalid ciphertext length for AES-CTR framing.");

                byte[] ct = ReadExactlyOrInvalid(reader, ctLen, "CTR ciphertext");
                EncTrace.FrameCtr("Decrypt", module, totalLength, nonce, ctLen, rowGroupOrdinal, columnOrdinal, pageOrdinal);


                // IV = nonce(12) || 0x00000001 (big-endian)
                byte[] iv16 = new byte[16];
                Buffer.BlockCopy(nonce, 0, iv16, 0, NonceLen);
                iv16[12] = 0x00;
                iv16[13] = 0x00;
                iv16[14] = 0x00;
                iv16[15] = 0x01;

                using var cipherStream = new MemoryStream(ct, writable: false);
                using var plainStream = new MemoryStream(ctLen);
                AesCtrTransform(FooterEncryptionKey!, iv16, cipherStream, plainStream);

                return plainStream.ToArray();
            }

            // Non-page modules remain GCM-framed (length|nonce|ciphertext|tag)
            return base.Decrypt(reader, module, rowGroupOrdinal, columnOrdinal, pageOrdinal);
        }

        private static byte[] EncryptCtrPageBody(byte[] body, byte[] key) {
            if(key == null || (key.Length != 16 && key.Length != 24 && key.Length != 32))
                throw new InvalidDataException("Missing or invalid AES key for AES-GCM-CTR-V1 encryption.");

            // nonce(12) for framing; IV = nonce(12) || 00 00 00 01 (counter starts at 1)
            byte[] nonce12 = new byte[NonceLength];
#if NET8_0_OR_GREATER
    RandomNumberGenerator.Fill(nonce12);
#else
            using(var rng = RandomNumberGenerator.Create())
                rng.GetBytes(nonce12);
#endif

            byte[] iv16 = new byte[16];
            Buffer.BlockCopy(nonce12, 0, iv16, 0, NonceLength);
            iv16[12] = 0x00;
            iv16[13] = 0x00;
            iv16[14] = 0x00;
            iv16[15] = 0x01; // big-endian counter starts at 1

            // Optional but recommended: enforce per-key page count limit
            // (call the instance method if this lives inside your EncryptionBase)
            // CountPageEncryption();

            using var inMs = new MemoryStream(body, writable: false);
            using var outMs = new MemoryStream(body.Length);
            AesCtrTransform(key, iv16, inMs, outMs);  // must increment last 4 bytes as big-endian counter
            byte[] ct = outMs.ToArray();

            // CTR framing: length(4 LE) | nonce(12) | ciphertext
            int payloadLen = NonceLength + ct.Length;

            byte[] framed = new byte[4 + payloadLen];

            // Always emit LE length, regardless of platform endianness
            byte[] lenLE = BitConverter.GetBytes(payloadLen);
            if(!BitConverter.IsLittleEndian)
                Array.Reverse(lenLE);
            Buffer.BlockCopy(lenLE, 0, framed, 0, 4);

            Buffer.BlockCopy(nonce12, 0, framed, 4, NonceLength);
            Buffer.BlockCopy(ct, 0, framed, 4 + NonceLength, ct.Length);
            return framed;
        }


        public override byte[] EncryptDataPage(
            byte[] body,
            short rowGroupOrdinal,
            short columnOrdinal,
            short pageOrdinal
        ) {
            CountPageEncryption();
            return EncryptCtrPageBody(body, FooterEncryptionKey!);
        }

        public override byte[] EncryptDictionaryPage(
            byte[] body,
            short rowGroupOrdinal,
            short columnOrdinal
        ) {
            CountPageEncryption();
            return EncryptCtrPageBody(body, FooterEncryptionKey!);
        }

        private static void AesCtrTransform(byte[] key, byte[] iv16, Stream inputStream, Stream outputStream) {
            if(key == null)
                throw new ArgumentNullException(nameof(key));
            if(iv16 == null)
                throw new ArgumentNullException(nameof(iv16));
            if(iv16.Length != 16)
                throw new ArgumentException("IV must be 16 bytes for AES-CTR.", nameof(iv16));
            if(inputStream == null)
                throw new ArgumentNullException(nameof(inputStream));
            if(outputStream == null)
                throw new ArgumentNullException(nameof(outputStream));

            using var aes = Aes.Create();
            aes.Mode = CipherMode.ECB;
            aes.Padding = PaddingMode.None;
            aes.Key = key;

            const int blockSize = 16;
            byte[] counter = (byte[])iv16.Clone();
            byte[] inBuf = new byte[blockSize];
            byte[] ksBlock = new byte[blockSize];

            using ICryptoTransform ecbEncryptor = aes.CreateEncryptor(aes.Key, new byte[blockSize]); // IV unused for ECB

            int read;
            while((read = inputStream.Read(inBuf, 0, blockSize)) > 0) {
                // Generate keystream for current counter
                ecbEncryptor.TransformBlock(counter, 0, blockSize, ksBlock, 0);

                // XOR (partial for last chunk)
                for(int i = 0; i < read; i++) {
                    inBuf[i] = (byte)(inBuf[i] ^ ksBlock[i]);
                }
                outputStream.Write(inBuf, 0, read);

                // Increment only the last 4 bytes (big-endian)
                for(int p = 15; p >= 12; p--) {
                    if(++counter[p] != 0)
                        break;
                }
                // overflow check (should never happen in practice, as it would require >2^32 blocks = >64TB per page)
                bool wrapped = true;
                for(int p = 12; p <= 15; p++) {
                    if(counter[p] != 0) { wrapped = false; break; }
                }
                if(wrapped) {
                    throw new CryptographicException("AES-CTR counter overflow (exceeded 2^32-1 blocks).");
                }
            }
        }
    }
}

using System;
using System.IO;
using Parquet.Meta.Proto;

namespace Parquet.Encryption {
    /// <summary>
    /// AES-GCM v1 decryption for all Parquet modular-encryption modules.
    /// Module framing (per spec):
    ///   length (4 LE) | nonce (12) | ciphertext | tag (16)
    /// AAD:
    ///   aad = AadPrefix || (AadFileUnique || moduleId || [rowGroupLE16] || [columnLE16] || [pageLE16])
    /// </summary>
    internal class AES_GCM_V1_Encryption : EncryptionBase {
        // sane default max (64MB) - protects against OOM attacks
        const int MaxEncryptedModule = 64 * 1024 * 1024;

        private const int NonceLength = 12;
        private const int TagLength = 16;

        public AES_GCM_V1_Encryption() { }

        public override byte[] BloomFilterBitset(ThriftCompactProtocolReader reader, short rowGroupOrdinal, short columnOrdinal)
            => Decrypt(reader, Meta.ParquetModules.BloomFilter_Bitset, rowGroupOrdinal, columnOrdinal);

        public override byte[] BloomFilterHeader(ThriftCompactProtocolReader reader, short rowGroupOrdinal, short columnOrdinal)
            => Decrypt(reader, Meta.ParquetModules.BloomFilter_Header, rowGroupOrdinal, columnOrdinal);

        public override byte[] DecryptColumnIndex(ThriftCompactProtocolReader reader, short rowGroupOrdinal, short columnOrdinal)
            => Decrypt(reader, Meta.ParquetModules.ColumnIndex, rowGroupOrdinal, columnOrdinal);

        public override byte[] DecryptColumnMetaData(ThriftCompactProtocolReader reader, short rowGroupOrdinal, short columnOrdinal)
            => Decrypt(reader, Meta.ParquetModules.ColumnMetaData, rowGroupOrdinal, columnOrdinal);

        public override byte[] DecryptDataPage(ThriftCompactProtocolReader reader, short rowGroupOrdinal, short columnOrdinal, short pageOrdinal)
            => Decrypt(reader, Meta.ParquetModules.Data_Page, rowGroupOrdinal, columnOrdinal, pageOrdinal);

        public override byte[] DecryptDataPageHeader(ThriftCompactProtocolReader reader, short rowGroupOrdinal, short columnOrdinal, short pageOrdinal)
            => Decrypt(reader, Meta.ParquetModules.Data_PageHeader, rowGroupOrdinal, columnOrdinal, pageOrdinal);

        public override byte[] DecryptDictionaryPage(ThriftCompactProtocolReader reader, short rowGroupOrdinal, short columnOrdinal)
            => Decrypt(reader, Meta.ParquetModules.Dictionary_Page, rowGroupOrdinal, columnOrdinal);

        public override byte[] DecryptDictionaryPageHeader(ThriftCompactProtocolReader reader, short rowGroupOrdinal, short columnOrdinal)
            => Decrypt(reader, Meta.ParquetModules.Dictionary_PageHeader, rowGroupOrdinal, columnOrdinal);

        public override byte[] DecryptFooter(ThriftCompactProtocolReader reader)
            => Decrypt(reader, Meta.ParquetModules.Footer);

        public override byte[] DecryptOffsetIndex(ThriftCompactProtocolReader reader, short rowGroupOrdinal, short columnOrdinal)
            => Decrypt(reader, Meta.ParquetModules.OffsetIndex, rowGroupOrdinal, columnOrdinal);

        /// <summary>
        /// Shared AES-GCM decrypt path for all modules.
        /// Framing: length(4 LE) | nonce(12) | ciphertext | tag(16)
        /// </summary>
        protected virtual byte[] Decrypt(
            ThriftCompactProtocolReader reader,
            Meta.ParquetModules module,
            short? rowGroupOrdinal = null,
            short? columnOrdinal = null,
            short? pageOrdinal = null
        ) {
            if(FooterEncryptionKey is null || FooterEncryptionKey.Length == 0)
                throw new InvalidDataException("Missing decryption key for AES-GCM-V1 decryption.");

            // Spec framing: length(4 LE) | nonce(12) | ciphertext | tag(16)
            byte[] lenBytes = ReadExactlyOrInvalid(reader, 4, "GCM length").EnsureLittleEndian();
            int totalLength = BitConverter.ToInt32(lenBytes, 0);

            const int NonceLen = 12;
            const int TagLen = 16;

            if(totalLength < NonceLen + TagLen)
                throw new InvalidDataException($"Encrypted GCM buffer too small ({totalLength} bytes).");

            byte[] nonce = ReadExactlyOrInvalid(reader, NonceLen, "GCM nonce");
            int ctLen = totalLength - NonceLen - TagLen;
            if(ctLen < 0)
                throw new InvalidDataException("Invalid ciphertext length for AES-GCM framing.");

            byte[] ct = ReadExactlyOrInvalid(reader, ctLen, "GCM ciphertext");
            byte[] tag = ReadExactlyOrInvalid(reader, TagLen, "GCM tag");

            EncTrace.FrameGcm("Decrypt", module, totalLength, nonce, ctLen, tag, rowGroupOrdinal, columnOrdinal, pageOrdinal);

            // AAD = prefix || suffix(file-unique, module, ordinals)
            byte[] aad = BuildAad(module, rowGroupOrdinal, columnOrdinal, pageOrdinal);

            // Pull prefix & file-unique from the instance for logging + AAD construction
            byte[] prefix = AadPrefix ?? Array.Empty<byte>();
            byte[] fileUnique = AadFileUnique ?? throw new InvalidDataException("Missing AadFileUnique for AES-GCM decryption.");


            EncTrace.Aad("Decrypt", prefix, fileUnique, aad, module, rowGroupOrdinal, columnOrdinal, pageOrdinal);

            // Decrypt
            byte[] pt = new byte[ctLen];
            CryptoHelpers.GcmDecryptOrThrow(FooterEncryptionKey!, nonce, ct, tag, pt, aad);

            return pt;
        }

        // Core GCM encrypt for any module
        internal byte[] EncryptModuleGcm(
            byte[] plaintext,
            Meta.ParquetModules module,
            short? rowGroupOrdinal = null,
            short? columnOrdinal = null,
            short? pageOrdinal = null
        ) {
            if(FooterEncryptionKey == null || FooterEncryptionKey.Length == 0)
                throw new InvalidDataException("Missing key for AES-GCM-V1 encryption.");

            byte[] nonce = new byte[NonceLength];
            CryptoHelpers.FillNonce12(nonce);
            byte[] aad = BuildAad(module, rowGroupOrdinal, columnOrdinal, pageOrdinal);

            byte[] tag = new byte[TagLength];
            byte[] ct = new byte[plaintext.Length];

            CryptoHelpers.GcmEncryptOrThrow(FooterEncryptionKey!, nonce, plaintext, ct, tag, aad);
            CountGcmInvocation();

            return FrameGcm(nonce, ct, tag);
        }

        // ---- Per-module convenience wrappers (match your decryptors) ----

        public override byte[] EncryptFooter(byte[] plaintext)
            => EncryptModuleGcm(plaintext, Meta.ParquetModules.Footer);

        public override byte[] EncryptDictionaryPageHeader(byte[] header, short rowGroupOrdinal, short columnOrdinal)
            => EncryptModuleGcm(header, Meta.ParquetModules.Dictionary_PageHeader, rowGroupOrdinal, columnOrdinal);

        public override byte[] EncryptDataPageHeader(byte[] header, short rowGroupOrdinal, short columnOrdinal, short pageOrdinal)
            => EncryptModuleGcm(header, Meta.ParquetModules.Data_PageHeader, rowGroupOrdinal, columnOrdinal, pageOrdinal);

        public override byte[] EncryptDataPage(byte[] header, short rowGroupOrdinal, short columnOrdinal, short pageOrdinal)
            => EncryptModuleGcm(header, Meta.ParquetModules.Data_Page, rowGroupOrdinal, columnOrdinal, pageOrdinal);

        public override byte[] EncryptDictionaryPage(byte[] body, short rowGroupOrdinal, short columnOrdinal)
            => EncryptModuleGcm(body, Meta.ParquetModules.Dictionary_Page, rowGroupOrdinal, columnOrdinal);

        public override byte[] EncryptColumnMetaData(byte[] bytes, short rowGroupOrdinal, short columnOrdinal)
            => EncryptModuleGcm(bytes, Meta.ParquetModules.ColumnMetaData, rowGroupOrdinal, columnOrdinal);

        public override byte[] EncryptColumnIndex(byte[] bytes, short rowGroupOrdinal, short columnOrdinal)
            => EncryptModuleGcm(bytes, Meta.ParquetModules.ColumnIndex, rowGroupOrdinal, columnOrdinal);

        public override byte[] EncryptOffsetIndex(byte[] bytes, short rowGroupOrdinal, short columnOrdinal)
            => EncryptModuleGcm(bytes, Meta.ParquetModules.OffsetIndex, rowGroupOrdinal, columnOrdinal);

        public override byte[] EncryptBloomFilterHeader(byte[] bytes, short rowGroupOrdinal, short columnOrdinal)
            => EncryptModuleGcm(bytes, Meta.ParquetModules.BloomFilter_Header, rowGroupOrdinal, columnOrdinal);

        public override byte[] EncryptBloomFilterBitset(byte[] bytes, short rowGroupOrdinal, short columnOrdinal)
            => EncryptModuleGcm(bytes, Meta.ParquetModules.BloomFilter_Bitset, rowGroupOrdinal, columnOrdinal);
    }
}

using System;
using System.IO;
using System.Security.Cryptography;

namespace Parquet.Encryption {
    static class CryptoHelpers {
        // Parquet uses 128-bit (16-byte) GCM tags everywhere.
        private const int GcmTagSizeBytes = 16;

        public static void FillNonce12(byte[] nonce) {
#if NET6_0_OR_GREATER
            RandomNumberGenerator.Fill(nonce);
#else
            using var rng = RandomNumberGenerator.Create();
            rng.GetBytes(nonce);
#endif
        }

        public static void GcmEncryptOrThrow(
            byte[] key,
            ReadOnlySpan<byte> nonce,
            ReadOnlySpan<byte> plaintext,
            Span<byte> ciphertext,
            Span<byte> tag,
            ReadOnlySpan<byte> aad) {
#if NET8_0_OR_GREATER
            using var gcm = new AesGcm(key, GcmTagSizeBytes);
            gcm.Encrypt(nonce, plaintext, ciphertext, tag, aad);
#elif NET7_0_OR_GREATER || NET6_0_OR_GREATER || NET5_0_OR_GREATER || NETCOREAPP3_0_OR_GREATER || NETSTANDARD2_1
            using var gcm = new AesGcm(key);
            gcm.Encrypt(nonce, plaintext, ciphertext, tag, aad);
#else
            throw new PlatformNotSupportedException("AES-GCM is not available on netstandard2.0. Target netstandard2.1 or .NET 6+.");
#endif
        }

        public static void GcmDecryptOrThrow(
    byte[] key,
    ReadOnlySpan<byte> nonce,
    ReadOnlySpan<byte> ciphertext,
    ReadOnlySpan<byte> tag,
    Span<byte> plaintext,
    ReadOnlySpan<byte> aad) {
#if NET8_0_OR_GREATER
            using var gcm = new AesGcm(key, GcmTagSizeBytes);
            gcm.Decrypt(nonce, ciphertext, tag, plaintext, aad);
#elif NET7_0_OR_GREATER || NET6_0_OR_GREATER || NET5_0_OR_GREATER || NETCOREAPP3_0_OR_GREATER || NETSTANDARD2_1
            using var gcm = new AesGcm(key);
            gcm.Decrypt(nonce, ciphertext, tag, plaintext, aad);
#else
            throw new PlatformNotSupportedException("AES-GCM is not available on netstandard2.0. Target netstandard2.1 or .NET 6+.");
#endif
        }

        public static bool FixedTimeEquals(ReadOnlySpan<byte> a, ReadOnlySpan<byte> b) {
#if NET6_0_OR_GREATER || NETSTANDARD2_1
            return CryptographicOperations.FixedTimeEquals(a, b);
#else
            if(a.Length != b.Length)
                return false;
            int diff = 0;
            for(int i = 0; i < a.Length; i++)
                diff |= a[i] ^ b[i];
            return diff == 0;
#endif
        }

        // Write a plaintext footer and append nonce|tag per PF spec.
        // AAD = BuildAad(Footer) || footerBytes; plaintext is empty.
        internal static (byte[] Nonce12, byte[] Tag16) ComputePlaintextFooterSignature(
            byte[] footerBytes, byte[] signingKey, byte[] parquetAad) {
            if(signingKey == null || signingKey.Length == 0)
                throw new InvalidDataException("Footer signing key is required.");

            // Nonce
            byte[] nonce = new byte[12];
            FillNonce12(nonce);

            // AAD' = parquetAAD || footerBytes
            byte[] aadPrime = new byte[parquetAad.Length + footerBytes.Length];
            Buffer.BlockCopy(parquetAad, 0, aadPrime, 0, parquetAad.Length);
            Buffer.BlockCopy(footerBytes, 0, aadPrime, parquetAad.Length, footerBytes.Length);

            // Tag over empty plaintext
            byte[] tag = new byte[16];
            CryptoHelpers.GcmEncryptOrThrow(
                signingKey,
                nonce,
                plaintext: ReadOnlySpan<byte>.Empty,
                ciphertext: Span<byte>.Empty,
                tag: tag.AsSpan(),
                aad: aadPrime);

            return (nonce, tag);
        }

        public static byte[] DeriveKeyFromUtf8(string baseKeyUtf8, string label, int expectedLen) {
            byte[] baseBytes = System.Text.Encoding.UTF8.GetBytes(baseKeyUtf8);
            using var sha256 = System.Security.Cryptography.SHA256.Create();
            sha256.TransformBlock(baseBytes, 0, baseBytes.Length, null, 0);
            sha256.TransformBlock(new byte[] { 0 }, 0, 1, null, 0);
            byte[] labelBytes = System.Text.Encoding.UTF8.GetBytes(label);
            sha256.TransformFinalBlock(labelBytes, 0, labelBytes.Length);
            byte[] full = sha256.Hash!;
            if(expectedLen is 16 or 24 or 32) {
                byte[] result = new byte[expectedLen];
                Buffer.BlockCopy(full, 0, result, 0, expectedLen);
                return result;
            }
            throw new ArgumentOutOfRangeException(nameof(expectedLen));
        }
    }
}

using System;
using System.IO;
using System.Linq;
using System.Security.Cryptography;
using System.Text;
using System.Threading;
using Parquet.Meta.Proto;
using Parquet.Meta;
using Encoding = System.Text.Encoding;
using System.Buffers.Binary;

namespace Parquet.Encryption {
    internal abstract class EncryptionBase {
        private const uint MaxInvocations = 0xFFFF_FFFF; // 2^32 - per NIST text
        private const long MaxPagesPerKey = 1L << 31;    // Parquet guidance (~2 billion)

        private long _gcmInvocations;
        private long _pageEncryptions; // data + dictionary pages

        internal byte[]? AadPrefix { get; set; }
        internal byte[]? FooterEncryptionKey { get; set; }
        internal byte[]? AadFileUnique { get; set; }

        public static byte[] DecryptFooter(
            ThriftCompactProtocolReader reader,
            string footerEncryptionKey,
            string? aadPrefix,
            out EncryptionBase decrypter) {
            if(string.IsNullOrEmpty(footerEncryptionKey)) {
                throw new ArgumentException($"Encrypted parquet files require an {nameof(footerEncryptionKey)} value");
            }

            var cryptoMetaData = FileCryptoMetaData.Read(reader);
            if(cryptoMetaData.EncryptionAlgorithm.AESGCMV1 is not null) {
                decrypter = new AES_GCM_V1_Encryption();
                decrypter.AadFileUnique = cryptoMetaData.EncryptionAlgorithm.AESGCMV1.AadFileUnique ?? Array.Empty<byte>();
                if(cryptoMetaData.EncryptionAlgorithm.AESGCMV1.SupplyAadPrefix == true) {
                    if(string.IsNullOrEmpty(aadPrefix)) {
                        throw new InvalidDataException("This file requires an AAD (additional authenticated data) prefix in order to be decrypted.");
                    }
                    decrypter.AadPrefix = Encoding.UTF8.GetBytes(aadPrefix);
                } else {
                    decrypter.AadPrefix = cryptoMetaData.EncryptionAlgorithm.AESGCMV1.AadPrefix ?? Array.Empty<byte>();
                }
            } else if(cryptoMetaData.EncryptionAlgorithm.AESGCMCTRV1 is not null) {
                decrypter = new AES_GCM_CTR_V1_Encryption();

                AesGcmCtrV1 alg = cryptoMetaData.EncryptionAlgorithm.AESGCMCTRV1;
                decrypter.AadFileUnique = alg.AadFileUnique
                    ?? throw new InvalidDataException("Encrypted file is missing aad_file_unique.");

                if(alg.SupplyAadPrefix == true) {
                    if(string.IsNullOrEmpty(aadPrefix))
                        throw new InvalidDataException("This file requires an AAD (additional authenticated data) prefix in order to be decrypted.");
                    decrypter.AadPrefix = Encoding.UTF8.GetBytes(aadPrefix);
                } else {
                    decrypter.AadPrefix = alg.AadPrefix ?? Array.Empty<byte>();
                }
            } else {
                throw new NotSupportedException("No encryption algorithm defined");
            }

            decrypter.FooterEncryptionKey = ParseKeyString(footerEncryptionKey);
            return decrypter.DecryptFooter(reader);
        }

        public abstract byte[] DecryptFooter(ThriftCompactProtocolReader reader);
        public abstract byte[] DecryptColumnMetaData(ThriftCompactProtocolReader reader, short rowGroupOrdinal, short columnOrdinal);
        public abstract byte[] DecryptDataPage(ThriftCompactProtocolReader reader, short rowGroupOrdinal, short columnOrdinal, short pageOrdinal);
        public abstract byte[] DecryptDictionaryPage(ThriftCompactProtocolReader reader, short rowGroupOrdinal, short columnOrdinal);
        public abstract byte[] DecryptDataPageHeader(ThriftCompactProtocolReader reader, short rowGroupOrdinal, short columnOrdinal, short pageOrdinal);
        public abstract byte[] DecryptDictionaryPageHeader(ThriftCompactProtocolReader reader, short rowGroupOrdinal, short columnOrdinal);
        public abstract byte[] DecryptColumnIndex(ThriftCompactProtocolReader reader, short rowGroupOrdinal, short columnOrdinal);
        public abstract byte[] DecryptOffsetIndex(ThriftCompactProtocolReader reader, short rowGroupOrdinal, short columnOrdinal);
        public abstract byte[] BloomFilterHeader(ThriftCompactProtocolReader reader, short rowGroupOrdinal, short columnOrdinal);
        public abstract byte[] BloomFilterBitset(ThriftCompactProtocolReader reader, short rowGroupOrdinal, short columnOrdinal);

        // ----------------- Encryption (for writing) ----------------

        public static (EncryptionBase Encrypter, Meta.FileCryptoMetaData CryptoMeta)
        CreateEncryptorForWrite(
            // used as the footer ENCRYPTION key in encrypted-footer mode,
            // and as the SIGNING key in plaintext-footer mode
            string encryptionOrSigningKey,
            byte[]? aadPrefixBytes,
            bool supplyAadPrefix,
            bool useCtrVariant,
            byte[]? aadFileUnique = null
        ) {
            if(string.IsNullOrWhiteSpace(encryptionOrSigningKey))
                throw new ArgumentException("Encryption/Signing key is required.", nameof(encryptionOrSigningKey));

            if(supplyAadPrefix && (aadPrefixBytes == null || aadPrefixBytes.Length == 0))
                throw new ArgumentException("SupplyAadPrefix=true requires aadPrefixBytes to be provided at write time.", nameof(aadPrefixBytes));

            byte[] key = ParseKeyString(encryptionOrSigningKey);
            if(!(key.Length is 16 or 24 or 32))
                throw new ArgumentException("AES key must be 128/192/256-bit.");

            // If the writer chose "supply prefix" mode, we must have the prefix now to compute AAD,
            // even though it will NOT be stored in the file (alg.AadPrefix = null).
            if(supplyAadPrefix && (aadPrefixBytes == null || aadPrefixBytes.Length == 0))
                throw new ArgumentException("SupplyAadPrefix=true requires aadPrefixBytes to be provided at write time.", nameof(aadPrefixBytes));

            // AAD file-unique (used in AAD suffix for all modules)
            if(aadFileUnique is null || aadFileUnique.Length == 0) {
                aadFileUnique = new byte[16];
#if NET8_0_OR_GREATER
        System.Security.Cryptography.RandomNumberGenerator.Fill(aadFileUnique);
#else
                using(var rng = System.Security.Cryptography.RandomNumberGenerator.Create())
                    rng.GetBytes(aadFileUnique);
#endif
            }

            EncryptionBase enc = useCtrVariant
                ? new AES_GCM_CTR_V1_Encryption()
                : new AES_GCM_V1_Encryption();

            // For encrypted-footer: this is the footer encryption key.
            // For plaintext-footer: this is the signing key (used only to compute/verify GCM tag).
            enc.FooterEncryptionKey = key;

            // The encrypter keeps the prefix bytes so it can compute AAD at write time,
            // regardless of whether we store it in the file.
            enc.AadFileUnique = aadFileUnique;
            enc.AadPrefix = aadPrefixBytes ?? Array.Empty<byte>();

            // Build algorithm section to serialize into FileCryptoMetaData (encrypted footer)
            // or FileMetaData.EncryptionAlgorithm (plaintext footer). If supplyAadPrefix==true,
            // do NOT store the prefix in the file.
            var alg = new Meta.EncryptionAlgorithm();
            if(useCtrVariant) {
                alg.AESGCMCTRV1 = new Meta.AesGcmCtrV1 {
                    AadFileUnique = aadFileUnique,
                    SupplyAadPrefix = supplyAadPrefix,
                    AadPrefix = supplyAadPrefix ? null : aadPrefixBytes
                };
            } else {
                alg.AESGCMV1 = new Meta.AesGcmV1 {
                    AadFileUnique = aadFileUnique,
                    SupplyAadPrefix = supplyAadPrefix,
                    AadPrefix = supplyAadPrefix ? null : aadPrefixBytes
                };
            }

            var cryptoMeta = new Meta.FileCryptoMetaData {
                EncryptionAlgorithm = alg
                // key_metadata can be filled by caller if you integrate a KMS
            };

            return (enc, cryptoMeta);
        }

        public static EncryptionBase CreateFromCryptoMeta(
            ThriftCompactProtocolReader reader,
            string footerEncryptionKey,
            string? aadPrefix
        ) {
            if(string.IsNullOrWhiteSpace(footerEncryptionKey))
                throw new ArgumentException($"Encrypted parquet files require an {nameof(footerEncryptionKey)} value");

            var cryptoMetaData = Meta.FileCryptoMetaData.Read(reader);

            EncryptionBase decrypter;
            if(cryptoMetaData.EncryptionAlgorithm.AESGCMV1 is not null) {
                decrypter = new AES_GCM_V1_Encryption();
                Meta.AesGcmV1 alg = cryptoMetaData.EncryptionAlgorithm.AESGCMV1;
                decrypter.AadFileUnique = alg.AadFileUnique
                    ?? throw new InvalidDataException("Encrypted file is missing aad_file_unique.");
                if(alg.SupplyAadPrefix == true) {
                    if(string.IsNullOrEmpty(aadPrefix))
                        throw new InvalidDataException("This file requires an AAD (additional authenticated data) prefix in order to be decrypted.");
                    decrypter.AadPrefix = Encoding.UTF8.GetBytes(aadPrefix);
                } else {
                    decrypter.AadPrefix = alg.AadPrefix ?? Array.Empty<byte>();
                }
            } else if(cryptoMetaData.EncryptionAlgorithm.AESGCMCTRV1 is not null) {
                decrypter = new AES_GCM_CTR_V1_Encryption();
                Meta.AesGcmCtrV1 alg = cryptoMetaData.EncryptionAlgorithm.AESGCMCTRV1;
                decrypter.AadFileUnique = alg.AadFileUnique
                    ?? throw new InvalidDataException("Encrypted file is missing aad_file_unique.");
                if(alg.SupplyAadPrefix == true) {
                    if(string.IsNullOrEmpty(aadPrefix))
                        throw new InvalidDataException("This file requires an AAD (additional authenticated data) prefix in order to be decrypted.");
                    decrypter.AadPrefix = Encoding.UTF8.GetBytes(aadPrefix);
                } else {
                    decrypter.AadPrefix = alg.AadPrefix ?? Array.Empty<byte>();
                }
            } else {
                throw new NotSupportedException("No encryption algorithm defined");
            }

            decrypter.FooterEncryptionKey = ParseKeyString(footerEncryptionKey);
            return decrypter;
        }

        /// <summary>
        /// Create a decrypter instance from a FileMetaData.EncryptionAlgorithm (plaintext footer mode).
        /// </summary>
        public static EncryptionBase CreateFromAlgorithm(
            Meta.EncryptionAlgorithm alg,
            string footerEncryptionKey,
            string? aadPrefix) {

            if(string.IsNullOrWhiteSpace(footerEncryptionKey))
                throw new ArgumentException($"Encrypted columns require a {nameof(FooterEncryptionKey)}.");

            EncryptionBase decrypter;
            if(alg.AESGCMV1 is not null) {
                Meta.AesGcmV1 a = alg.AESGCMV1;
                decrypter = new AES_GCM_V1_Encryption {
                    AadFileUnique = a.AadFileUnique ?? Array.Empty<byte>(),
                    AadPrefix = a.SupplyAadPrefix == true
                        ? (!string.IsNullOrEmpty(aadPrefix) ? Encoding.UTF8.GetBytes(aadPrefix) : throw new InvalidDataException("AAD prefix required for this file."))
                        : (a.AadPrefix ?? Array.Empty<byte>())
                };
            } else if(alg.AESGCMCTRV1 is not null) {
                Meta.AesGcmCtrV1 a = alg.AESGCMCTRV1;
                decrypter = new AES_GCM_CTR_V1_Encryption {
                    AadFileUnique = a.AadFileUnique ?? Array.Empty<byte>(),
                    AadPrefix = a.SupplyAadPrefix == true
                        ? (!string.IsNullOrEmpty(aadPrefix) ? Encoding.UTF8.GetBytes(aadPrefix) : throw new InvalidDataException("AAD prefix required for this file."))
                        : (a.AadPrefix ?? Array.Empty<byte>())
                };
            } else {
                throw new NotSupportedException("No encryption algorithm defined.");
            }

            decrypter.FooterEncryptionKey = ParseKeyString(footerEncryptionKey);
            return decrypter;
        }

        public abstract byte[] EncryptFooter(byte[] plaintext);
        public abstract byte[] EncryptColumnMetaData(byte[] bytes, short rowGroupOrdinal, short columnOrdinal);
        public abstract byte[] EncryptDataPageHeader(byte[] header, short rowGroupOrdinal, short columnOrdinal, short pageOrdinal);
        public abstract byte[] EncryptDataPage(byte[] body, short rowGroupOrdinal, short columnOrdinal, short pageOrdinal);
        public abstract byte[] EncryptDictionaryPageHeader(byte[] header, short rowGroupOrdinal, short columnOrdinal);
        public abstract byte[] EncryptDictionaryPage(byte[] body, short rowGroupOrdinal, short columnOrdinal);
        public abstract byte[] EncryptColumnIndex(byte[] bytes, short rowGroupOrdinal, short columnOrdinal);
        public abstract byte[] EncryptOffsetIndex(byte[] bytes, short rowGroupOrdinal, short columnOrdinal);
        public abstract byte[] EncryptBloomFilterHeader(byte[] bytes, short rowGroupOrdinal, short columnOrdinal);
        public abstract byte[] EncryptBloomFilterBitset(byte[] bytes, short rowGroupOrdinal, short columnOrdinal);

        internal static byte[] ParseKeyString(string keyString) {
            if(string.IsNullOrWhiteSpace(keyString))
                throw new ArgumentException(
                    "EncryptionKey must be 128/192/256-bit. " +
                    "Provide as Base64, hex, or a UTF-8 string of 16/24/32 bytes.");

            static bool IsHexChar(char c) =>
                (c >= '0' && c <= '9') ||
                (c >= 'a' && c <= 'f') ||
                (c >= 'A' && c <= 'F');

            bool allHexChars = keyString.All(IsHexChar);
            bool evenLength = (keyString.Length % 2) == 0;

            // 1) HEX — only if it would decode to 16/24/32 bytes
            if(evenLength && allHexChars) {
                int decodedLen = keyString.Length / 2;
                if(decodedLen is 16 or 24 or 32) {
                    byte[] bytes = new byte[decodedLen];
                    for(int i = 0; i < decodedLen; i++) {
                        int hi = Convert.ToInt32(keyString[2 * i].ToString(), 16);
                        int lo = Convert.ToInt32(keyString[(2 * i) + 1].ToString(), 16);
                        bytes[i] = (byte)((hi << 4) + lo);
                    }
                    return bytes;
                }
                // Don't throw yet; try Base64/UTF-8 fallbacks first.
            }

            // 2) Base64 (standard or URL-safe, with optional padding)
            try {
                string s = keyString.Replace('-', '+').Replace('_', '/');
                switch(s.Length % 4) {
                    case 2:
                        s += "==";
                        break;
                    case 3:
                        s += "=";
                        break;
                }
                byte[] b64 = Convert.FromBase64String(s);
                if(b64.Length is 16 or 24 or 32)
                    return b64;
            } catch {
                // ignore and fall through
            }

            // 3) Raw UTF-8 bytes
            byte[] utf8 = Encoding.UTF8.GetBytes(keyString);
            if(utf8.Length is 16 or 24 or 32)
                return utf8;

            // If it looked hex but wasn't a valid hex key length, surface a helpful message.
            if(evenLength && allHexChars)
                throw new ArgumentException("Hex key must decode to 16/24/32 bytes.");

            throw new ArgumentException(
                "EncryptionKey must be 128/192/256-bit. " +
                "Provide as Base64, hex, or a UTF-8 string of 16/24/32 bytes.");
        }

        protected static byte[] ReadExactlyOrInvalid(ThriftCompactProtocolReader reader, int length, string context) {
            try {
                return reader.ReadBytesExactly(length);
            } catch(IOException ex) {
                // Normalize framing issues to InvalidDataException for tests + callers
                EncTrace.Log($"ReadExactly failed ctx='{context}' need={length}: {ex.Message}");
                throw new InvalidDataException($"{context}: expected {length} bytes but stream ended early.", ex);
            }
        }

        protected void CountGcmInvocation() {
            long v = Interlocked.Increment(ref _gcmInvocations);
            if(v > MaxInvocations) {
                throw new CryptographicException("AES-GCM invocation limit exceeded for this key.");
            }
        }

        protected void CountPageEncryption() {
            long v = Interlocked.Increment(ref _pageEncryptions);
            if(v > MaxPagesPerKey) {
                throw new CryptographicException("Per-key page encryption limit (~2^31) exceeded.");
            }
        }

        protected static byte[] FrameGcm(ReadOnlySpan<byte> nonce12, ReadOnlySpan<byte> ciphertext, ReadOnlySpan<byte> tag16) {
            int payloadLen = nonce12.Length + ciphertext.Length + tag16.Length; // >= 28
            byte[] framed = new byte[4 + payloadLen];
            BinaryPrimitives.WriteInt32LittleEndian(framed.AsSpan(0, 4), payloadLen);
            nonce12.CopyTo(framed.AsSpan(4));
            ciphertext.CopyTo(framed.AsSpan(4 + nonce12.Length));
            tag16.CopyTo(framed.AsSpan(4 + nonce12.Length + ciphertext.Length));
            return framed;
        }

        // CTR pages: [lenLE][nonce(12)][ciphertext]
        protected static byte[] FrameCtr(ReadOnlySpan<byte> nonce12, ReadOnlySpan<byte> ciphertext) {
            int payloadLen = nonce12.Length + ciphertext.Length; // >= 12
            byte[] framed = new byte[4 + payloadLen];
            BinaryPrimitives.WriteInt32LittleEndian(framed.AsSpan(0, 4), payloadLen);
            nonce12.CopyTo(framed.AsSpan(4));
            ciphertext.CopyTo(framed.AsSpan(4 + nonce12.Length));
            return framed;
        }


        internal byte[] BuildAad(
                Meta.ParquetModules module,
                short? rowGroupOrdinal = null,
                short? columnOrdinal = null,
                short? pageOrdinal = null
            ) {

            byte[] prefix = AadPrefix ?? Array.Empty<byte>();
            byte[] fileUnique = AadFileUnique ?? throw new InvalidDataException("Missing AadFileUnique.");
            byte[] suffix = BuildAadSuffix(fileUnique, module, rowGroupOrdinal, columnOrdinal, pageOrdinal);

            byte[] aad = new byte[prefix.Length + suffix.Length];
            Buffer.BlockCopy(prefix, 0, aad, 0, prefix.Length);
            Buffer.BlockCopy(suffix, 0, aad, prefix.Length, suffix.Length);
            return aad;
        }

        internal static byte[] BuildAadSuffix(
            byte[] aadFileUnique,
            Meta.ParquetModules module,
            short? rowGroupOrdinal,
            short? columnOrdinal,
            short? pageOrdinal
        ) {

            using var ms = new MemoryStream();
            ms.Write(aadFileUnique, 0, aadFileUnique.Length);
            ms.WriteByte((byte)module);
            if(rowGroupOrdinal.HasValue) {
                byte[] le = BitConverter.GetBytes(rowGroupOrdinal.Value).EnsureLittleEndian();
                ms.Write(le, 0, le.Length);
            }
            if(columnOrdinal.HasValue) {
                byte[] le = BitConverter.GetBytes(columnOrdinal.Value).EnsureLittleEndian();
                ms.Write(le, 0, le.Length);
            }
            if(pageOrdinal.HasValue) {
                byte[] le = BitConverter.GetBytes(pageOrdinal.Value).EnsureLittleEndian();
                ms.Write(le, 0, le.Length);
            }
            return ms.ToArray();
        }
    }
}

// Parquet/Encryption/EncTrace.cs
using System;
using System.Buffers.Binary;
using System.Security.Cryptography;
using System.Text;

namespace Parquet.Encryption {
    internal static class EncTrace {
        // Turn on with: PARQUET_ENC_TRACE=1
        private static readonly bool Enabled =
            string.Equals(Environment.GetEnvironmentVariable("PARQUET_ENC_TRACE"), "1", StringComparison.OrdinalIgnoreCase);

        internal static void Log(string msg) {
#if DEBUG
            if(Enabled)
                System.Console.Error.WriteLine($"[parquet-enc] {msg}");
#endif
        }

        internal static string Hex(ReadOnlySpan<byte> s, int max = 48) {
            if(s.IsEmpty)
                return "(empty)";
            int n = Math.Min(s.Length, max);
            var sb = new StringBuilder((n * 2) + 16);
            for(int i = 0; i < n; i++)
                sb.AppendFormat("{0:x2}", s[i]);
            if(s.Length > n)
                sb.Append($"..(+{s.Length - n})");
            return sb.ToString();
        }

        internal static string KeyId(ReadOnlySpan<byte> key) {
            // Don’t dump keys; show length + short fingerprint for correlation
            using var sha = SHA256.Create();
            byte[] d = sha.ComputeHash(key.ToArray());
            return $"len={key.Length}, sha256={Hex(d.AsSpan(0, 8))}";
        }

        internal static void FrameGcm(string where, Meta.ParquetModules m, int totalLen,
                                      ReadOnlySpan<byte> nonce12, int ctLen, ReadOnlySpan<byte> tag16,
                                      short? rg, short? col, short? pg) {
            Log($"{where} GCM frame m={m} len={totalLen} ct={ctLen} nonce={Hex(nonce12, 12)} tag={Hex(tag16, 16)} rg={rg} col={col} pg={pg}");
        }

        internal static void FrameCtr(string where, Meta.ParquetModules m, int totalLen,
                                      ReadOnlySpan<byte> nonce12, int ctLen,
                                      short? rg, short? col, short? pg) {
            Log($"{where} CTR frame m={m} len={totalLen} ct={ctLen} nonce={Hex(nonce12, 12)} rg={rg} col={col} pg={pg}");
        }

        internal static void Aad(string where, ReadOnlySpan<byte> prefix, ReadOnlySpan<byte> fileUnique,
                                 ReadOnlySpan<byte> aad, Meta.ParquetModules m,
                                 short? rg, short? col, short? pg) {
            Log($"{where} AAD m={m} rg={rg} col={col} pg={pg} prefix=({prefix.Length}) {Hex(prefix)} fileUnique={Hex(fileUnique)} fullAAD=({aad.Length}) {Hex(aad)}");
        }

        internal static void Alg(string where, string alg, bool supplyPrefix, bool hasStoredPrefix) {
            Log($"{where} alg={alg} supplyPrefix={supplyPrefix} storedPrefix={(hasStoredPrefix ? "yes" : "no")}");
        }

        internal static void FooterMode(string where, string mode) {
            Log($"{where} footerMode={mode}");
        }

        internal static void VerifyAttempt(string where, string variant, ReadOnlySpan<byte> nonce12, ReadOnlySpan<byte> tag16, bool ok) {
            Log($"{where} verify={variant} nonce={Hex(nonce12, 12)} tag={Hex(tag16, 16)} ok={ok}");
        }
    }
}

using System.IO;
using System.Linq;
using Parquet.Data;
using Parquet.File;
using Parquet.Meta;
using Parquet.Schema;

namespace Parquet {
    /// <summary>
    /// Internal data structure helpers
    /// </summary>
    static class ThriftExtensions {
        public static bool IsAnnotatedWithAny(this SchemaElement schemaElement, ConvertedType[] convertedTypes) {
            if(convertedTypes == null || convertedTypes.Length == 0)
                return false;

            return
               schemaElement.ConvertedType != null &&
               convertedTypes.Any(ct => ct == schemaElement.ConvertedType);
        }

        public static bool IsNullable(this SchemaElement schemaElement) {
            return schemaElement.RepetitionType != FieldRepetitionType.REQUIRED;
        }

        public static FieldPath GetPath(this ColumnChunk columnChunk) {
            return new FieldPath(columnChunk.MetaData!.PathInSchema);
        }

        public static string Describe(this SchemaElement se) {
            return $"[n: {se.Name}, t: {se.Type}, ct: {se.ConvertedType}, rt: {se.RepetitionType}, c: {se.NumChildren}]";
        }

        public static FieldPath GetPath(this ThriftFooter footer, ColumnChunk cc) {
            if(cc.MetaData?.PathInSchema != null)
                return new FieldPath(cc.MetaData.PathInSchema);

            // Fallback: look up the SchemaElement for this chunk and derive path from the schema tree
            SchemaElement? se = footer.GetSchemaElement(cc);
            if(se != null)
                return footer.GetPath(se);

            throw new InvalidDataException("Unable to determine column path (no MetaData.PathInSchema and no matching schema element).");
        }
    }
}

using System;
using System.IO.Compression;
using IronCompress;
using Parquet.Encryption;

namespace Parquet.File {
    static class Compressor {
        private static readonly Iron _iron = new();

        public static IronCompressResult Compress(CompressionMethod method, ReadOnlySpan<byte> input, CompressionLevel compressionLevel) => _iron.Compress(ToCodec(method), input, compressionLevel: compressionLevel);

        public static IronCompressResult Decompress(CompressionMethod method, ReadOnlySpan<byte> input, int outLength) {
            EncTrace.Log($"Decompress codec={method} in={input.Length} outLenHint={outLength}");
            return _iron.Decompress(ToCodec(method), input, outLength);
        }

        private static Codec ToCodec(CompressionMethod method) {
            switch(method) {
                case CompressionMethod.Snappy:
                    return Codec.Snappy;
                case CompressionMethod.Gzip:
                    return Codec.Gzip;
                case CompressionMethod.Lzo:
                    return Codec.LZO;
                case CompressionMethod.Brotli:
                    return Codec.Brotli;
                case CompressionMethod.LZ4:
                    return Codec.LZ4;
                case CompressionMethod.Zstd:
                    return Codec.Zstd;
                case CompressionMethod.Lz4Raw:
                    return Codec.LZ4;
                default:
                    throw new NotSupportedException($"{method} not supported");
            }
        }
    }
}

using System;
using System.Buffers;
using System.IO;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;
using IronCompress;
using Parquet.Data;
using Parquet.Schema;
using Parquet.Encodings;
using Parquet.Meta;
using Parquet.Meta.Proto;
using Parquet.Extensions;
using System.Collections.Generic;

namespace Parquet.File {

    /// <summary>
    /// Reader for Parquet data column
    /// </summary>
    class DataColumnReader {
        private readonly DataField _dataField;
        private readonly Stream _inputStream;
        private readonly ColumnChunk _thriftColumnChunk;
        private readonly SchemaElement? _schemaElement;
        private readonly ThriftFooter _footer;
        private readonly ParquetOptions _options;
        private readonly DataColumnStatistics? _stats;
        private readonly RowGroup _rowGroup;

        internal DataColumnReader(
           DataField dataField,
           Stream inputStream,
           ColumnChunk thriftColumnChunk,
           DataColumnStatistics? stats,
           ThriftFooter footer,
           ParquetOptions? parquetOptions,
           RowGroup rowGroup) {
            _dataField = dataField ?? throw new ArgumentNullException(nameof(dataField));
            _inputStream = inputStream ?? throw new ArgumentNullException(nameof(inputStream));
            _thriftColumnChunk = thriftColumnChunk ?? throw new ArgumentNullException(nameof(thriftColumnChunk));
            _stats = stats;
            _footer = footer ?? throw new ArgumentNullException(nameof(footer));
            _options = parquetOptions ?? throw new ArgumentNullException(nameof(parquetOptions));
            _rowGroup = rowGroup ?? throw new ArgumentNullException(nameof(rowGroup));

            dataField.EnsureAttachedToSchema(nameof(dataField));

            _schemaElement = _footer.GetSchemaElement(_thriftColumnChunk);
        }

        /// <summary>
        /// Return data column statistics
        /// </summary>
        /// <returns>Data column statistics or null</returns>
        public DataColumnStatistics? GetColumnStatistics() => _stats;

        /// <summary>
        /// Read entire column data
        /// </summary>
        /// <param name="cancellationToken">Cancellation token</param>
        /// <returns>DataColumn object filled in with data</returns>
        /// <exception cref="NotSupportedException">Unsupported page type</exception>
        public async Task<DataColumn> ReadAsync(CancellationToken cancellationToken = default) {

            // how many values are in column chunk, as there may be multiple data pages
            int totalValuesInChunk = (int)_thriftColumnChunk.MetaData!.NumValues;
            int definedValuesCount = totalValuesInChunk;
            if(_stats?.NullCount != null)
                definedValuesCount -= (int)_stats.NullCount.Value;

            using var pc = new PackedColumn(_dataField, totalValuesInChunk, definedValuesCount);

            // seek to first page (dict or data)
            long fileOffset = GetFileOffset(out bool isDictionaryPageOffset);
            _inputStream.Seek(fileOffset, SeekOrigin.Begin);

            // NEW: only treat this column as encrypted when the chunk *has* CryptoMetadata
            bool useEncryption = _thriftColumnChunk.CryptoMetadata is not null;

            short pageOrdinal = 0;
            short columnOrdinal = (short)_rowGroup.Columns.IndexOf(_thriftColumnChunk);
            if(columnOrdinal < 0)
                throw new InvalidDataException("Could not determine column ordinal");

            while(pc.ValuesRead < totalValuesInChunk) {
                if(useEncryption) {

                    // Dictionary (encrypted) if positioned there
                    if(isDictionaryPageOffset) {
                        byte[] dictHdr = _footer.Decrypter!.DecryptDictionaryPageHeader(
                            new ThriftCompactProtocolReader(_inputStream),
                            _rowGroup.Ordinal!.Value, columnOrdinal);

                        using(var ms = new MemoryStream(dictHdr)) {
                            var hdrReader = new ThriftCompactProtocolReader(ms);
                            var ph = PageHeader.Read(hdrReader);

                            byte[] dictBody = _footer.Decrypter.DecryptDictionaryPage(
                                new ThriftCompactProtocolReader(_inputStream),
                                _rowGroup.Ordinal!.Value, columnOrdinal);

                            ReadDictionaryPageFromBuffer(ph, dictBody, pc);
                        }

                        isDictionaryPageOffset = false;
                        continue;
                    }

                    // Footer-key encrypted column
                    if(_thriftColumnChunk.CryptoMetadata?.ENCRYPTIONWITHFOOTERKEY != null) {
                        if(_footer.Decrypter is null)
                            throw new InvalidDataException(
                                "This file contains encrypted columns, but no footer key/decrypter is available. " +
                                "Provide ParquetOptions.FooterEncryptionKey (and AAD prefix if required).");
                        // header (GCM)
                        byte[] hdr = _footer.Decrypter!.DecryptDataPageHeader(
                            new ThriftCompactProtocolReader(_inputStream),
                            _rowGroup.Ordinal!.Value, columnOrdinal, pageOrdinal);

                        using var ms = new MemoryStream(hdr);
                        var hdrReader = new ThriftCompactProtocolReader(ms);
                        var ph = PageHeader.Read(hdrReader);

                        // body (algo depends on profile; decrypter handles it)
                        byte[] body = _footer.Decrypter.DecryptDataPage(
                            new ThriftCompactProtocolReader(_inputStream),
                            _rowGroup.Ordinal!.Value, columnOrdinal, pageOrdinal);

                        if(ph.Type == PageType.DATA_PAGE)
                            ReadDataPageV1FromBuffer(ph, body, pc);
                        else if(ph.Type == PageType.DATA_PAGE_V2)
                            ReadDataPageV2FromBuffer(ph, body, pc, totalValuesInChunk);
                        else if(ph.Type == PageType.DICTIONARY_PAGE)
                            ReadDictionaryPageFromBuffer(ph, body, pc);
                        else
                            throw new InvalidDataException($"Unsupported page type '{ph.Type}'");

                        pageOrdinal++;
                    } else if(_thriftColumnChunk.CryptoMetadata?.ENCRYPTIONWITHCOLUMNKEY != null) {
                        EncryptionWithColumnKey ck = _thriftColumnChunk.CryptoMetadata.ENCRYPTIONWITHCOLUMNKEY;
                        string? keyString = _footer.Encrypter is null
                            ? null
                            : _options.ColumnKeyResolver?.Invoke(ck.PathInSchema, ck.KeyMetadata);

                        if(string.IsNullOrWhiteSpace(keyString))
                            throw new InvalidDataException(
                                $"Column key is required to read encrypted column '{string.Join(".", ck.PathInSchema)}'.");

                        byte[] columnKey = Encryption.EncryptionBase.ParseKeyString(keyString!);

                        // Temporarily swap the decrypter key for this column
                        byte[]? originalKey = _footer.Decrypter!.FooterEncryptionKey;
                        _footer.Decrypter.FooterEncryptionKey = columnKey;
                        try {
                            // Dictionary page header/body (GCM)
                            if(isDictionaryPageOffset) {
                                byte[] dictHdr = _footer.Decrypter!.DecryptDictionaryPageHeader(
                                    new ThriftCompactProtocolReader(_inputStream),
                                    _rowGroup.Ordinal!.Value, columnOrdinal);

                                using var ms = new MemoryStream(dictHdr);
                                var hdrReader2 = new ThriftCompactProtocolReader(ms);
                                var ph = PageHeader.Read(hdrReader2);

                                byte[] dictBody = _footer.Decrypter.DecryptDictionaryPage(
                                    new ThriftCompactProtocolReader(_inputStream),
                                    _rowGroup.Ordinal!.Value, columnOrdinal);

                                ReadDictionaryPageFromBuffer(ph, dictBody, pc);
                                isDictionaryPageOffset = false;
                            }

                            // Data pages loop (same as footer-key path, but using the swapped key)
                            // header (GCM)
                            byte[] hdr = _footer.Decrypter!.DecryptDataPageHeader(
                                new ThriftCompactProtocolReader(_inputStream),
                                _rowGroup.Ordinal!.Value, columnOrdinal, pageOrdinal);

                            using var msHdr = new MemoryStream(hdr);
                            var hdrReader = new ThriftCompactProtocolReader(msHdr);
                            var ph2 = PageHeader.Read(hdrReader);

                            // body
                            byte[] body = _footer.Decrypter.DecryptDataPage(
                                new ThriftCompactProtocolReader(_inputStream),
                                _rowGroup.Ordinal!.Value, columnOrdinal, pageOrdinal);

                            if(ph2.Type == PageType.DATA_PAGE)
                                ReadDataPageV1FromBuffer(ph2, body, pc);
                            else if(ph2.Type == PageType.DATA_PAGE_V2)
                                ReadDataPageV2FromBuffer(ph2, body, pc, totalValuesInChunk);
                            else if(ph2.Type == PageType.DICTIONARY_PAGE)
                                ReadDictionaryPageFromBuffer(ph2, body, pc);
                            else
                                throw new InvalidDataException($"Unsupported page type '{ph2.Type}'");

                            pageOrdinal++;
                        } finally {
                            _footer.Decrypter!.FooterEncryptionKey = originalKey!;
                        }
                    } else {
                        // Shouldn't happen because useEncryption implies CryptoMetadata != null,
                        // but keep a defensive fallback to plaintext.
                        var plainReader = new ThriftCompactProtocolReader(_inputStream);
                        PageHeader ph = PageHeader.Read(plainReader);

                        switch(ph.Type) {
                            case PageType.DICTIONARY_PAGE:
                                await ReadDictionaryPage(ph, pc);
                                break;
                            case PageType.DATA_PAGE:
                                await ReadDataPageV1Async(ph, pc);
                                break;
                            case PageType.DATA_PAGE_V2:
                                await ReadDataPageV2Async(ph, pc, totalValuesInChunk);
                                break;
                            default:
                                throw new NotSupportedException($"can't read page type {ph.Type}");
                        }
                    }
                } else {
                    // Plaintext column (either plaintext file, or encrypted file with plaintext columns)
                    var protoReader = new ThriftCompactProtocolReader(_inputStream);
                    PageHeader ph = PageHeader.Read(protoReader);

                    switch(ph.Type) {
                        case PageType.DICTIONARY_PAGE:
                            await ReadDictionaryPage(ph, pc);
                            break;
                        case PageType.DATA_PAGE:
                            await ReadDataPageV1Async(ph, pc);
                            break;
                        case PageType.DATA_PAGE_V2:
                            await ReadDataPageV2Async(ph, pc, totalValuesInChunk);
                            break;
                        default:
                            throw new NotSupportedException($"can't read page type {ph.Type}");
                    }
                }
            }

            // all data ready
            DataColumn column = pc.Unpack();
            if(_stats != null)
                column.Statistics = _stats;
            return column;
        }

        private static Span<byte> AsMutableSpan(ReadOnlySpan<byte> src, out byte[] rented) {
            rented = ArrayPool<byte>.Shared.Rent(src.Length);
            src.CopyTo(rented);
            return rented.AsSpan(0, src.Length);
        }

        private async Task<IronCompress.IronCompressResult> ReadPageDataAsync(PageHeader ph) {

            byte[] data = ArrayPool<byte>.Shared.Rent(ph.CompressedPageSize);

            int totalBytesRead = 0, remainingBytes = ph.CompressedPageSize;
            do {
                int bytesRead = await _inputStream.ReadAsync(data, totalBytesRead, remainingBytes);
                totalBytesRead += bytesRead;
                remainingBytes -= bytesRead;
            }
            while(remainingBytes != 0);

            if(_thriftColumnChunk.MetaData!.Codec == CompressionCodec.UNCOMPRESSED) {
                return new IronCompress.IronCompressResult(data, Codec.Snappy, false, ph.CompressedPageSize, ArrayPool<byte>.Shared);
            }

            return Compressor.Decompress((CompressionMethod)(int)_thriftColumnChunk.MetaData.Codec,
                data.AsSpan(0, ph.CompressedPageSize),
                ph.UncompressedPageSize);
        }

        private async Task<IronCompress.IronCompressResult> ReadPageDataV2Async(PageHeader ph) {

            int pageSize = ph.CompressedPageSize;

            byte[] data = ArrayPool<byte>.Shared.Rent(pageSize);

            int totalBytesRead = 0, remainingBytes = pageSize;
            do {
                int bytesRead = await _inputStream.ReadAsync(data, totalBytesRead, remainingBytes);
                totalBytesRead += bytesRead;
                remainingBytes -= bytesRead;
            }
            while(remainingBytes != 0);

            return new IronCompress.IronCompressResult(data, Codec.Snappy, false, pageSize, ArrayPool<byte>.Shared);
        }

        private async ValueTask ReadDictionaryPage(PageHeader ph, PackedColumn pc) {

            if(pc.HasDictionary)
                throw new InvalidOperationException("dictionary already read");

            //Dictionary page format: the entries in the dictionary - in dictionary order - using the plain encoding.
            using IronCompress.IronCompressResult bytes = await ReadPageDataAsync(ph);

            // Dictionary should not contains null values
            Array dictionary = _dataField.CreateArray(ph.DictionaryPageHeader!.NumValues);

            ParquetPlainEncoder.Decode(dictionary, 0, ph.DictionaryPageHeader.NumValues,
                   _schemaElement!, bytes.AsSpan(), out int dictionaryOffset);

            pc.AssignDictionary(dictionary);
        }

        private long GetFileOffset(out bool isDictionaryPageOffset) {
            //https://stackoverflow.com/a/55226688/1458738
            long dictionaryPageOffset = _thriftColumnChunk.MetaData?.DictionaryPageOffset ?? 0;
            long firstDataPageOffset = _thriftColumnChunk.MetaData!.DataPageOffset;
            if(dictionaryPageOffset > 0 && dictionaryPageOffset < firstDataPageOffset) {
                // if there's a dictionary and it's before the first data page, start from there
                isDictionaryPageOffset = true;
                return dictionaryPageOffset;
            }
            isDictionaryPageOffset = false;
            return firstDataPageOffset;
        }

        private async Task ReadDataPageV1Async(PageHeader ph, PackedColumn pc) {
            using IronCompress.IronCompressResult bytes = await ReadPageDataAsync(ph);

            if(ph.DataPageHeader == null) {
                throw new ParquetException($"column '{_dataField.Path}' is missing data page header, file is corrupt");
            }

            int dataUsed = 0;
            int allValueCount = (int)_thriftColumnChunk.MetaData!.NumValues;
            int pageValueCount = ph.DataPageHeader.NumValues;

            if(_dataField.MaxRepetitionLevel > 0) {
                //todo: use rented buffers, but be aware that rented length can be more than requested so underlying logic relying on array length must be fixed too.

                int levelsRead = ReadLevels(
                    bytes.AsSpan(), _dataField.MaxRepetitionLevel,
                    pc.GetWriteableRepetitionLevelSpan(),
                    pageValueCount, null, out int usedLength);
                pc.MarkRepetitionLevels(levelsRead);
                dataUsed += usedLength;
            }

            int defNulls = 0;
            if(_dataField.MaxDefinitionLevel > 0) {
                int levelsRead = ReadLevels(
                    bytes.AsSpan().Slice(dataUsed), _dataField.MaxDefinitionLevel,
                    pc.GetWriteableDefinitionLevelSpan(),
                    pageValueCount, null, out int usedLength);
                dataUsed += usedLength;
                defNulls = pc.MarkDefinitionLevels(levelsRead, _dataField.MaxDefinitionLevel);
            }

            // try to be clever to detect how many elements to read
            int dataElementCount = pageValueCount - defNulls;

            ReadColumn(
                bytes.AsSpan().Slice(dataUsed),
                ph.DataPageHeader.Encoding,
                allValueCount, dataElementCount,
                pc);
        }

        private async Task ReadDataPageV2Async(PageHeader ph, PackedColumn pc, long maxValues) {
            if(ph.DataPageHeaderV2 == null) {
                throw new ParquetException($"column '{_dataField.Path}' is missing data page header, file is corrupt");
            }

            using IronCompress.IronCompressResult bytes = await ReadPageDataV2Async(ph);
            int dataUsed = 0;

            if(_dataField.MaxRepetitionLevel > 0) {
                //todo: use rented buffers, but be aware that rented length can be more than requested so underlying logic relying on array length must be fixed too.
                int levelsRead = ReadLevels(bytes.AsSpan(),
                    _dataField.MaxRepetitionLevel, pc.GetWriteableRepetitionLevelSpan(),
                    ph.DataPageHeaderV2.NumValues, ph.DataPageHeaderV2.RepetitionLevelsByteLength, out int usedLength);
                dataUsed += usedLength;
                pc.MarkRepetitionLevels(levelsRead);
            }

            if(_dataField.MaxDefinitionLevel > 0) {
                int levelsRead = ReadLevels(bytes.AsSpan().Slice(dataUsed),
                    _dataField.MaxDefinitionLevel, pc.GetWriteableDefinitionLevelSpan(),
                    ph.DataPageHeaderV2.NumValues, ph.DataPageHeaderV2.DefinitionLevelsByteLength, out int usedLength);
                dataUsed += usedLength;
                pc.MarkDefinitionLevels(levelsRead);
            }

            int maxReadCount = ph.DataPageHeaderV2.NumValues - ph.DataPageHeaderV2.NumNulls;

            if((!(ph.DataPageHeaderV2.IsCompressed ?? false)) || _thriftColumnChunk.MetaData!.Codec == CompressionCodec.UNCOMPRESSED) {
                ReadColumn(bytes.AsSpan().Slice(dataUsed), ph.DataPageHeaderV2.Encoding, maxValues, maxReadCount, pc);
                return;
            }

            int dataSize = ph.CompressedPageSize - ph.DataPageHeaderV2.RepetitionLevelsByteLength -
                           ph.DataPageHeaderV2.DefinitionLevelsByteLength;

            int decompressedSize = ph.UncompressedPageSize - ph.DataPageHeaderV2.RepetitionLevelsByteLength -
                                   ph.DataPageHeaderV2.DefinitionLevelsByteLength;

            IronCompress.IronCompressResult decompressedDataByes = Compressor.Decompress(
                (CompressionMethod)(int)_thriftColumnChunk.MetaData.Codec,
                bytes.AsSpan().Slice(dataUsed),
                decompressedSize);

            ReadColumn(decompressedDataByes.AsSpan(),
                ph.DataPageHeaderV2.Encoding,
                maxValues, maxReadCount,
                pc);
        }

        private int ReadLevels(Span<byte> s, int maxLevel,
            Span<int> dest,
            int pageSize,
            int? length, out int usedLength) {

            int bitWidth = maxLevel.GetBitWidth();

            return RleBitpackedHybridEncoder.Decode(s, bitWidth, length, out usedLength, dest, pageSize);
        }

        private void ReadColumn(
            ReadOnlySpan<byte> src,
            Encoding encoding,
            long totalValuesInChunk,
            int totalValuesInPage,
            PackedColumn pc
        ) {
            // Bridge to APIs that require Span<byte>
            Span<byte> spanSrc = AsMutableSpan(src, out byte[] rented);
            try {
                switch(encoding) {
                    case Encoding.PLAIN: // 0
                    {
                            Array plainData = pc.GetPlainDataToReadInto(out int offset);
                            ParquetPlainEncoder.Decode(
                                plainData,
                                offset,
                                totalValuesInPage,
                                _schemaElement!,
                                spanSrc,
                                out int read);
                            pc.MarkUsefulPlainData(read);
                            break;
                        }

                    case Encoding.PLAIN_DICTIONARY: // 2
                    case Encoding.RLE_DICTIONARY:   // 8
                    {
                            Span<int> idxDest = pc.AllocateOrGetDictionaryIndexes(totalValuesInPage);
                            int indexCount = ReadRleDictionary(spanSrc, totalValuesInPage, idxDest);
                            pc.MarkUsefulDictionaryIndexes(indexCount);
                            pc.Checkpoint();
                            break;
                        }

                    case Encoding.RLE: // 3
                    {
                            Array plainData = pc.GetPlainDataToReadInto(out int offset);

                            if(_dataField.ClrType == typeof(bool)) {
                                // Decode to temp int[] then map to bool[]
                                int[] tmp = new int[plainData.Length];
                                int read = RleBitpackedHybridEncoder.Decode(
                                    spanSrc,
                                    _schemaElement!.TypeLength ?? 0,
                                    spanSrc.Length,
                                    out int _,
                                    tmp.AsSpan(offset),
                                    totalValuesInPage);

                                bool[] tgt = (bool[])plainData;
                                for(int i = 0; i < read; i++)
                                    tgt[i + offset] = tmp[i] == 1;

                                pc.MarkUsefulPlainData(read);
                                pc.Checkpoint();
                            } else {
                                Span<int> dest = ((int[])plainData).AsSpan(offset);
                                int read = RleBitpackedHybridEncoder.Decode(
                                    spanSrc,
                                    _schemaElement!.TypeLength ?? 0,
                                    spanSrc.Length,
                                    out int _,
                                    dest,
                                    totalValuesInPage);

                                pc.MarkUsefulPlainData(read);
                                pc.Checkpoint();
                            }
                            break;
                        }

                    case Encoding.DELTA_BINARY_PACKED: // 5
                    {
                            Array plainData = pc.GetPlainDataToReadInto(out int offset);
                            int read = DeltaBinaryPackedEncoder.Decode(
                                spanSrc,
                                plainData,
                                offset,
                                totalValuesInPage,
                                out _);
                            pc.MarkUsefulPlainData(read);
                            break;
                        }

                    case Encoding.DELTA_LENGTH_BYTE_ARRAY: // 6
                    {
                            Array plainData = pc.GetPlainDataToReadInto(out int offset);
                            int read = DeltaLengthByteArrayEncoder.Decode(
                                spanSrc,
                                plainData,
                                offset,
                                totalValuesInPage);
                            pc.MarkUsefulPlainData(read);
                            break;
                        }

                    case Encoding.DELTA_BYTE_ARRAY: // 7
                    {
                            Array plainData = pc.GetPlainDataToReadInto(out int offset);
                            int read = DeltaByteArrayEncoder.Decode(
                                spanSrc,
                                plainData,
                                offset,
                                totalValuesInPage);
                            pc.MarkUsefulPlainData(read);
                            break;
                        }

                    case Encoding.BIT_PACKED:        // 4 (deprecated)
                    case Encoding.BYTE_STREAM_SPLIT: // 9
                    default:
                        throw new ParquetException($"encoding {encoding} is not supported.");
                }
            } finally {
                ArrayPool<byte>.Shared.Return(rented);
            }
        }

        private static int ReadRleDictionary(Span<byte> s, int maxReadCount, Span<int> dest) {
            int offset = 0;
            int destOffset = 0;
            int start = destOffset;
            int bitWidth = s[offset++];

            int length = s.Length - 1;

            //when bit width is zero reader must stop and just repeat zero maxValue number of times
            if(bitWidth == 0 || length == 0) {
                for(int i = 0; i < maxReadCount; i++) {
                    dest[destOffset++] = 0;
                }
            } else {
                if(length != 0) {
                    destOffset += RleBitpackedHybridEncoder.Decode(s.Slice(1), bitWidth, length, out int usedLength, dest, maxReadCount);
                }
            }

            return destOffset - start;
        }

        private static IronCompress.IronCompressResult DecompressWholePageFromBuffer(
            ReadOnlySpan<byte> pageBytes, int uncompressedSize, CompressionCodec codec) {
            if(codec == CompressionCodec.UNCOMPRESSED) {
                // mimic your ReadPageDataAsync contract using a rented buffer
                byte[] rented = ArrayPool<byte>.Shared.Rent(pageBytes.Length);
                pageBytes.CopyTo(rented);
                return new IronCompress.IronCompressResult(
                    rented, Codec.Snappy, false, pageBytes.Length, ArrayPool<byte>.Shared);
            }

            return Compressor.Decompress(
                (CompressionMethod)(int)codec, pageBytes, uncompressedSize);
        }

        private void ReadDictionaryPageFromBuffer(PageHeader ph, ReadOnlySpan<byte> pageBytes, PackedColumn pc) {
            if(pc.HasDictionary)
                throw new InvalidOperationException("dictionary already read");

            using IronCompress.IronCompressResult bytes =
                DecompressWholePageFromBuffer(pageBytes, ph.UncompressedPageSize, _thriftColumnChunk.MetaData!.Codec);

            Array dictionary = _dataField.CreateArray(ph.DictionaryPageHeader!.NumValues);
            ParquetPlainEncoder.Decode(dictionary, 0, ph.DictionaryPageHeader.NumValues,
                _schemaElement!, bytes.AsSpan(), out _);

            pc.AssignDictionary(dictionary);
        }

        private void ReadDataPageV1FromBuffer(PageHeader ph, ReadOnlySpan<byte> pageBytes, PackedColumn pc) {
            using IronCompress.IronCompressResult bytes =
                DecompressWholePageFromBuffer(pageBytes, ph.UncompressedPageSize, _thriftColumnChunk.MetaData!.Codec);

            if(ph.DataPageHeader == null)
                throw new ParquetException($"column '{_dataField.Path}' is missing data page header, file is corrupt");

            int used = 0;
            int allValues = (int)_thriftColumnChunk.MetaData!.NumValues;
            int pageValues = ph.DataPageHeader.NumValues;

            if(_dataField.MaxRepetitionLevel > 0) {
                int n = ReadLevels(bytes.AsSpan(), _dataField.MaxRepetitionLevel,
                    pc.GetWriteableRepetitionLevelSpan(), pageValues, null, out int u);
                pc.MarkRepetitionLevels(n);
                used += u;
            }

            int defNulls = 0;
            if(_dataField.MaxDefinitionLevel > 0) {
                int n = ReadLevels(bytes.AsSpan().Slice(used), _dataField.MaxDefinitionLevel,
                    pc.GetWriteableDefinitionLevelSpan(), pageValues, null, out int u);
                used += u;
                defNulls = pc.MarkDefinitionLevels(n, _dataField.MaxDefinitionLevel);
            }

            int dataCount = pageValues - defNulls;
            ReadColumn(bytes.AsSpan().Slice(used), ph.DataPageHeader.Encoding, allValues, dataCount, pc);
        }

        private void ReadDataPageV2FromBuffer(PageHeader ph, ReadOnlySpan<byte> pageBytes, PackedColumn pc, long maxValues) {
            if(ph.DataPageHeaderV2 == null)
                throw new ParquetException($"column '{_dataField.Path}' is missing data page header, file is corrupt");

            int used = 0;

            if(_dataField.MaxRepetitionLevel > 0) {
                int n = ReadLevels(pageBytes.ToArray(),
                    _dataField.MaxRepetitionLevel, pc.GetWriteableRepetitionLevelSpan(),
                    ph.DataPageHeaderV2.NumValues, ph.DataPageHeaderV2.RepetitionLevelsByteLength, out int u);
                used += u;
                pc.MarkRepetitionLevels(n);
            }

            if(_dataField.MaxDefinitionLevel > 0) {
                int n = ReadLevels(pageBytes.Slice(used).ToArray(),
                    _dataField.MaxDefinitionLevel, pc.GetWriteableDefinitionLevelSpan(),
                    ph.DataPageHeaderV2.NumValues, ph.DataPageHeaderV2.DefinitionLevelsByteLength, out int u);
                used += u;
                pc.MarkDefinitionLevels(n);
            }

            int maxRead = ph.DataPageHeaderV2.NumValues - ph.DataPageHeaderV2.NumNulls;

            bool notCompressed =
                (!(ph.DataPageHeaderV2.IsCompressed ?? false)) ||
                _thriftColumnChunk.MetaData!.Codec == CompressionCodec.UNCOMPRESSED;

            if(notCompressed) {
                ReadColumn(pageBytes.Slice(used).ToArray(), ph.DataPageHeaderV2.Encoding, maxValues, maxRead, pc);
                return;
            }

            int dataSize = ph.CompressedPageSize
                - ph.DataPageHeaderV2.RepetitionLevelsByteLength
                - ph.DataPageHeaderV2.DefinitionLevelsByteLength;

            int decompSize = ph.UncompressedPageSize
                - ph.DataPageHeaderV2.RepetitionLevelsByteLength
                - ph.DataPageHeaderV2.DefinitionLevelsByteLength;

            ColumnMetaData meta = _thriftColumnChunk.MetaData
                ?? throw new InvalidDataException("ColumnChunk.MetaData is missing");

            using IronCompress.IronCompressResult decomp = Compressor.Decompress(
                (CompressionMethod)(int)meta.Codec,
                pageBytes.Slice(used, dataSize),
                decompSize);

            ReadColumn(decomp.AsSpan(), ph.DataPageHeaderV2.Encoding, maxValues, maxRead, pc);
        }

    }
}

using System;
using System.Collections.Generic;
using System.IO;
using System.IO.Compression;
using System.Threading;
using System.Threading.Tasks;
using IronCompress;
using Microsoft.IO;
using Parquet.Data;
using Parquet.Encodings;
using Parquet.Extensions;
using Parquet.Meta;
using Parquet.Schema;

namespace Parquet.File {
    class DataColumnWriter {
        private readonly Stream _stream;
        private readonly ThriftFooter _footer;
        private readonly SchemaElement _schemaElement;
        private readonly CompressionMethod _compressionMethod;
        private readonly CompressionLevel _compressionLevel;
        private readonly Dictionary<string, string>? _keyValueMetadata;
        private readonly ParquetOptions _options;
        private static readonly RecyclableMemoryStreamManager _rmsMgr = new RecyclableMemoryStreamManager();
        private readonly short _rowGroupOrdinal;
        private readonly short _columnOrdinal;
        private short _pageOrdinal; // increments per DATA page only

        public DataColumnWriter(
            Stream stream,
            ThriftFooter footer,
            SchemaElement schemaElement,
            CompressionMethod compressionMethod,
            ParquetOptions options,
            CompressionLevel compressionLevel,
            Dictionary<string, string>? keyValueMetadata,
            short rowGroupOrdinal,
            short columnOrdinal
        ) {
            _stream = stream;
            _footer = footer;
            _schemaElement = schemaElement;
            _compressionMethod = compressionMethod;
            _compressionLevel = compressionLevel;
            _keyValueMetadata = keyValueMetadata;
            _options = options;
            _rmsMgr.Settings.MaximumSmallPoolFreeBytes = options.MaximumSmallPoolFreeBytes;
            _rmsMgr.Settings.MaximumLargePoolFreeBytes = options.MaximumLargePoolFreeBytes;
            _rowGroupOrdinal = rowGroupOrdinal;
            _columnOrdinal = columnOrdinal;
            _pageOrdinal = 0;
        }

        public async Task<ColumnChunk> WriteAsync(
            FieldPath fullPath,
            DataColumn column,
            CancellationToken cancellationToken = default
        ) {

            if(column == null)
                throw new ArgumentNullException(nameof(column));
            column.Field.EnsureAttachedToSchema(nameof(column));

            // Create the chunk as before
            ColumnChunk chunk = _footer.CreateColumnChunk(
                _compressionMethod, _stream, _schemaElement.Type!.Value, fullPath, column.NumValues, _keyValueMetadata);

            // Will we encrypt this column at all?
            bool writerHasEncrypter = _footer.Encrypter is not null;

            // Decide if this column uses a column-specific key or the footer key
            bool useColumnKey = false;
            byte[]? columnKeyBytes = null;
            byte[]? columnKeyMetadata = null;

            if(writerHasEncrypter) {
                // Build a stable path string to match user-supplied map (you can adapt to your convention)
                string pathStr = string.Join(".", fullPath.ToList());

                if(_options is not null &&
                   _options.ColumnKeys is not null &&
                   _options.ColumnKeys.TryGetValue(pathStr, out ParquetOptions.ColumnKeySpec? spec)) {

                    useColumnKey = true;
                    columnKeyBytes = Encryption.EncryptionBase.ParseKeyString(spec.Key);
                    columnKeyMetadata = spec.KeyMetadata;

                    // Advertise column crypto metadata (column-key case)
                    chunk.CryptoMetadata = new ColumnCryptoMetaData {
                        ENCRYPTIONWITHCOLUMNKEY = new EncryptionWithColumnKey {
                            PathInSchema = fullPath.ToList(),
                            KeyMetadata = columnKeyMetadata
                        }
                    };
                } else {
                    // Footer-key case
                    chunk.CryptoMetadata = new ColumnCryptoMetaData {
                        ENCRYPTIONWITHFOOTERKEY = new EncryptionWithFooterKey()
                    };
                }
            }

            // If we’re using a column key, temporarily swap it onto the encrypter so that
            // *all* per-column modules (page headers/bodies, indexes, bloom) are sealed with that key.
            byte[]? originalKey = null;
            if(writerHasEncrypter && useColumnKey) {
                originalKey = _footer.Encrypter!.FooterEncryptionKey;
                _footer.Encrypter.FooterEncryptionKey = columnKeyBytes!;
            }

            ColumnSizes sizes;
            try {
                // This writes dictionary + data pages (and encrypts them if encrypter != null)
                sizes = await WriteColumnAsync(chunk, column, _schemaElement, cancellationToken);
            } finally {
                if(writerHasEncrypter && useColumnKey) {
                    _footer.Encrypter!.FooterEncryptionKey = originalKey!;
                }
            }

            // Generate/attach stats to the (plaintext) ColumnMetaData we just produced
            chunk.MetaData!.Statistics = column.Statistics.ToThriftStatistics(_schemaElement);

            // Counters include page headers + bodies
            chunk.MetaData.TotalCompressedSize = sizes.CompressedSize;
            chunk.MetaData.TotalUncompressedSize = sizes.UncompressedSize;

            // ---- ColumnMetaData protection per spec (§5.3/§5.4) ----
            // If the column uses a *column-specific* key, we must serialize ColumnMetaData separately
            // and encrypt it with the column key, storing the result in encrypted_column_metadata.
            if(writerHasEncrypter && useColumnKey) {
                // 1) Serialize ColumnMetaData
                byte[] cmdPlain;
                using(var ms = new MemoryStream()) {
                    chunk.MetaData!.Write(new Meta.Proto.ThriftCompactProtocolWriter(ms));
                    cmdPlain = ms.ToArray();
                }

                // 2) Encrypt with the *column key* (swap again just for this operation)
                byte[]? originalKey2 = _footer.Encrypter!.FooterEncryptionKey;
                _footer.Encrypter.FooterEncryptionKey = columnKeyBytes!;
                try {
                    byte[] encCmd = _footer.Encrypter.EncryptColumnMetaData(
                        cmdPlain, _rowGroupOrdinal, _columnOrdinal);
                    chunk.EncryptedColumnMetadata = encCmd;
                    chunk.MetaData = null; // clear plaintext copy
                } finally {
                    _footer.Encrypter.FooterEncryptionKey = originalKey2!;
                }

                // 3) Adjust where meta_data lives according to footer mode:
                //    - Encrypted footer mode: omit meta_data entirely.
                //    - Plaintext footer mode: keep meta_data but strip sensitive stats so legacy readers can vectorize.
                bool encryptedFooterMode = _footer.Encrypter is not null && !(_options?.UsePlaintextFooter ?? false);
                if(encryptedFooterMode) {
                    chunk.MetaData = null;
                } else {
                    if(chunk.MetaData?.Statistics != null) {
                        chunk.MetaData.Statistics.MinValue = null;
                        chunk.MetaData.Statistics.MaxValue = null;
                        chunk.MetaData.Statistics.NullCount = null;
                        chunk.MetaData.Statistics.DistinctCount = null;
                    }
                }
            }

            return chunk;
        }

        class ColumnSizes {
            public int CompressedSize;
            public int UncompressedSize;
        }

        private async Task CompressAndWriteAsync(
            PageHeader ph,
            MemoryStream data,
            ColumnSizes cs,
            CancellationToken cancellationToken
        ) {
            // Compress (or pass-through) the page body first
            byte[]? borrowed;
            ReadOnlySpan<byte> plain = GetBytesFast(data, out borrowed);
            using IronCompress.IronCompressResult compressedData =
                _compressionMethod == CompressionMethod.None
                    ? new IronCompress.IronCompressResult(plain.ToArray(), Codec.Snappy, false)
                    : Compressor.Compress(_compressionMethod, plain, _compressionLevel);

            // Plaintext path (no encryption)
            if(_footer.Encrypter is null) {
                ph.UncompressedPageSize = (int)data.Length;
                ph.CompressedPageSize = compressedData.AsSpan().Length;

                using MemoryStream headerMs = _rmsMgr.GetStream();
                ph.Write(new Meta.Proto.ThriftCompactProtocolWriter(headerMs));
                int headerSize = (int)headerMs.Length;
                headerMs.Position = 0;

                await headerMs.CopyToAsync(_stream, 81920, cancellationToken: cancellationToken);
                _stream.WriteSpan(compressedData);

                cs.CompressedSize += headerSize + ph.CompressedPageSize;
                cs.UncompressedSize += headerSize + ph.UncompressedPageSize;
                return;
            }

            // Encrypted path
            // 1) Set plaintext uncompressed size in header
            ph.UncompressedPageSize = (int)data.Length;

            // 2) Prepare plaintext body bytes to encrypt
            byte[] bodyBytes = compressedData.AsSpan().ToArray();

            // 3) Encrypt page BODY first so we know the encrypted length
            //    GCM profile: page bodies must be framed as [nonce(12)][ciphertext][tag(16)]
            //    (No 4-byte length prefix in the page body frame)
            byte[] encBody = ph.Type == PageType.DICTIONARY_PAGE
                ? _footer.Encrypter.EncryptDictionaryPage(bodyBytes, _rowGroupOrdinal, _columnOrdinal)
                : _footer.Encrypter.EncryptDataPage(bodyBytes, _rowGroupOrdinal, _columnOrdinal, _pageOrdinal);

            // 4) Now set the header's CompressedPageSize to the ENCRYPTED body length
            // https://github.com/apache/parquet-format/blob/master/Encryption.md#51-encrypted-module-serialization
            ph.CompressedPageSize = encBody.Length;

            // 5) Serialize the PLAINTEXT header (with corrected sizes)
            byte[] headerBytes;
            using(MemoryStream headerMs = _rmsMgr.GetStream()) {
                ph.Write(new Meta.Proto.ThriftCompactProtocolWriter(headerMs));
                headerBytes = headerMs.ToArray();
            }

            // 6) Encrypt the header (header framing remains as per your GCM framing helper)
            byte[] encHeader = ph.Type == PageType.DICTIONARY_PAGE
                ? _footer.Encrypter.EncryptDictionaryPageHeader(headerBytes, _rowGroupOrdinal, _columnOrdinal)
                : _footer.Encrypter.EncryptDataPageHeader(headerBytes, _rowGroupOrdinal, _columnOrdinal, _pageOrdinal);

            // 7) Write encrypted header + encrypted body
            await _stream.WriteAsync(encHeader, 0, encHeader.Length, cancellationToken);
            await _stream.WriteAsync(encBody, 0, encBody.Length, cancellationToken);

            // 8) Update counters: "compressed" = on-disk encrypted sizes; "uncompressed" = original plain sizes
            cs.CompressedSize += encHeader.Length + encBody.Length;
            cs.UncompressedSize += headerBytes.Length + ph.UncompressedPageSize;
        }

        private async Task<ColumnSizes> WriteColumnAsync(ColumnChunk chunk, DataColumn column,
           SchemaElement tse,
           CancellationToken cancellationToken = default) {

            column.Field.EnsureAttachedToSchema(nameof(column));

            var r = new ColumnSizes();

            /*
             * Page header must preceeed actual data (compressed or not) however it contains both
             * the uncompressed and compressed data size which we don't know! This somehow limits
             * the write efficiency.
             */

            using var pc = new PackedColumn(column);
            pc.Pack(_options.UseDictionaryEncoding, _options.DictionaryEncodingThreshold);

            // dictionary page
            if(pc.HasDictionary) {
                chunk.MetaData!.DictionaryPageOffset = _stream.Position;
                PageHeader ph = _footer.CreateDictionaryPage(pc.Dictionary!.Length);
                using MemoryStream ms = _rmsMgr.GetStream();
                ParquetPlainEncoder.Encode(pc.Dictionary, 0, pc.Dictionary.Length,
                       tse,
                       ms, column.Statistics);
                await CompressAndWriteAsync(ph, ms, r, cancellationToken);
            }

            // data page
            using(MemoryStream ms = _rmsMgr.GetStream()) {
                chunk.MetaData!.DataPageOffset = _stream.Position;
                bool deltaEncode = column.IsDeltaEncodable && _options.UseDeltaBinaryPackedEncoding;
                // data page Num_values also does include NULLs
                PageHeader ph = _footer.CreateDataPage(column.NumValues, pc.HasDictionary, deltaEncode);
                if(pc.HasRepetitionLevels) {
                    WriteLevels(ms, pc.RepetitionLevels!, pc.RepetitionLevels!.Length, column.Field.MaxRepetitionLevel);
                }
                if(pc.HasDefinitionLevels) {
                    WriteLevels(ms, pc.DefinitionLevels!, column.DefinitionLevels!.Length, column.Field.MaxDefinitionLevel);
                }

                if(pc.HasDictionary) {
                    // dictionary indexes are always encoded with RLE
                    int[] indexes = pc.GetDictionaryIndexes(out int indexesLength)!;
                    int bitWidth = pc.Dictionary!.Length.GetBitWidth();
                    ms.WriteByte((byte)bitWidth);   // bit width is stored as 1 byte before encoded data
                    RleBitpackedHybridEncoder.Encode(ms, indexes.AsSpan(0, indexesLength), bitWidth);
                } else {
                    Array data = pc.GetPlainData(out int offset, out int count);
                    if(deltaEncode) {
                        DeltaBinaryPackedEncoder.Encode(data, offset, count, ms, column.Statistics);
                        chunk.MetaData!.Encodings[2] = Encoding.DELTA_BINARY_PACKED;
                    } else {
                        ParquetPlainEncoder.Encode(data, offset, count, tse, ms, pc.HasDictionary ? null : column.Statistics);
                    }
                }

                ph.DataPageHeader!.Statistics = column.Statistics.ToThriftStatistics(tse);
                await CompressAndWriteAsync(ph, ms, r, cancellationToken);
                _pageOrdinal++;
            }

            return r;
        }

        private static void WriteLevels(Stream s, Span<int> levels, int count, int maxValue) {
            int bitWidth = maxValue.GetBitWidth();
            RleBitpackedHybridEncoder.EncodeWithLength(s, bitWidth, levels.Slice(0, count));
        }

        private static ReadOnlySpan<byte> GetBytesFast(MemoryStream ms, out byte[]? borrowedArray) {
            borrowedArray = null;
            ArraySegment<byte> seg;
            if(ms.TryGetBuffer(out seg)) {
                return new ReadOnlySpan<byte>(seg.Array, seg.Offset, seg.Count);
            }
            byte[] arr = ms.ToArray();
            borrowedArray = arr;
            return new ReadOnlySpan<byte>(arr);
        }
    }
}

using System;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;
using Parquet.Encodings;
using Parquet.Schema;
using Parquet.Meta;
using Parquet.Meta.Proto;
using Parquet.Encryption;

namespace Parquet.File {
    class ThriftFooter {
        private readonly FileMetaData _fileMeta;
        private readonly ThriftSchemaTree _tree;

        internal static ThriftFooter Empty => new();

        internal ThriftFooter() {
            _fileMeta = new FileMetaData();
            _tree = new ThriftSchemaTree();
        }

        public ThriftFooter(FileMetaData fileMeta) {
            _fileMeta = fileMeta ?? throw new ArgumentNullException(nameof(fileMeta));
            _tree = new ThriftSchemaTree(_fileMeta.Schema);
        }

        internal static ParquetSchema Parse(params SchemaElement[] elements) {

            var slst = new List<SchemaElement> {
                new SchemaElement { Name = "root", NumChildren = 1 },
            };
            slst.AddRange(elements);

            return new ThriftFooter(new FileMetaData {
                Schema = slst
            }).CreateModelSchema(new ParquetOptions());
        }

        public ThriftFooter(ParquetSchema schema, long totalRowCount) {
            if(schema == null) {
                throw new ArgumentNullException(nameof(schema));
            }

            _fileMeta = CreateThriftSchema(schema);
            _fileMeta.NumRows = totalRowCount;


            // Looks like Spark is sensitive about this format. See https://github.com/aloneguid/parquet-dotnet/issues/261
#if DEBUG
            _fileMeta.CreatedBy = "Parquet.Net version LocalDev (build Local)";
#else
            _fileMeta.CreatedBy = $"Parquet.Net version {Globals.Version} (build {Globals.GithubSha})";
#endif
            _tree = new ThriftSchemaTree(_fileMeta.Schema);
        }

        public Dictionary<string, string> CustomMetadata {
            set {
                _fileMeta.KeyValueMetadata = null;
                if(value == null || value.Count == 0)
                    return;

                _fileMeta.KeyValueMetadata = value
                   .Select(kvp => new KeyValue { Key = kvp.Key, Value = kvp.Value })
                   .ToList();
            }
            get {
                if(_fileMeta.KeyValueMetadata == null || _fileMeta.KeyValueMetadata.Count == 0)
                    return new Dictionary<string, string>();

                return _fileMeta.KeyValueMetadata.ToDictionary(kv => kv.Key, kv => kv.Value!);
            }
        }

        public void Add(long totalRowCount) {
            _fileMeta.NumRows += totalRowCount;
        }

        public async Task<long> WriteAsync(Stream s, CancellationToken cancellationToken = default) {
            using var ms = new MemoryStream();
            _fileMeta.Write(new ThriftCompactProtocolWriter(ms));
            ms.Position = 0;
            await ms.CopyToAsync(s);
            return ms.Length;
        }

        public long Write(Stream s) {
            using var ms = new MemoryStream();
            _fileMeta.Write(new ThriftCompactProtocolWriter(ms));
            ms.Position = 0;
            ms.CopyTo(s);
            return ms.Length;
        }

        public SchemaElement? GetSchemaElement(ColumnChunk columnChunk) {
            if(columnChunk == null) {
                throw new ArgumentNullException(nameof(columnChunk));
            }

            var findPath = new FieldPath(columnChunk.MetaData!.PathInSchema);
            return _tree.Find(findPath)?.element;
        }

        public FieldPath GetPath(SchemaElement schemaElement) {
            var path = new List<string>();

            ThriftSchemaTree.Node? wrapped = _tree.Find(schemaElement);
            while(wrapped?.parent != null) {
                string? name = wrapped.element?.Name;
                if(name != null)
                    path.Add(name);
                wrapped = wrapped.parent;
            }

            path.Reverse();
            return new FieldPath(path);
        }

        public SchemaElement[] GetWriteableSchema() {
            return _fileMeta.Schema.Where(tse => tse.Type != null).ToArray();
        }

        public RowGroup AddRowGroup() {
            var rg = new RowGroup();
            _fileMeta.RowGroups ??= new List<RowGroup>();
            _fileMeta.RowGroups.Add(rg);

            // NEW: assign ordinal (short)
            rg.Ordinal = (short)(_fileMeta.RowGroups.Count - 1);

            return rg;
        }

        internal short GetRowGroupOrdinal(RowGroup rg) {
            if(!rg.Ordinal.HasValue) {
                throw new InvalidOperationException("RowGroup ordinal is missing.");
            }
            return rg.Ordinal.Value;
        }

        public ColumnChunk CreateColumnChunk(CompressionMethod compression, System.IO.Stream output,
            Parquet.Meta.Type columnType, FieldPath path, int valuesCount,
            Dictionary<string, string>? keyValueMetadata) {
            CompressionCodec codec = (CompressionCodec)(int)compression;

            var chunk = new ColumnChunk();
            long startPos = output.Position;
            chunk.FileOffset = startPos;
            chunk.MetaData = new ColumnMetaData();
            chunk.MetaData.NumValues = valuesCount;
            chunk.MetaData.Type = columnType;
            chunk.MetaData.Codec = codec;
            chunk.MetaData.DataPageOffset = startPos;
            chunk.MetaData.Encodings = new List<Encoding> {
                Encoding.RLE,
                Encoding.BIT_PACKED,
                Encoding.PLAIN
            };
            chunk.MetaData!.PathInSchema = path.ToList();
            chunk.MetaData!.Statistics = new Statistics();
            if(keyValueMetadata != null && keyValueMetadata.Count > 0) {
                chunk.MetaData.KeyValueMetadata = keyValueMetadata
                    .Select(kv => new KeyValue { Key = kv.Key, Value = kv.Value })
                    .ToList();
            }

            return chunk;
        }

        public PageHeader CreateDataPage(int valueCount, bool isDictionary, bool isDeltaEncodable) =>
            new PageHeader {
                Type = PageType.DATA_PAGE,
                DataPageHeader = new DataPageHeader {
                    Encoding = isDictionary
                        ? Encoding.PLAIN_DICTIONARY
                        : isDeltaEncodable ? Encoding.DELTA_BINARY_PACKED : Encoding.PLAIN,
                    DefinitionLevelEncoding = Encoding.RLE,
                    RepetitionLevelEncoding = Encoding.RLE,
                    NumValues = valueCount,
                    Statistics = new Statistics()
                }
            };

        public PageHeader CreateDictionaryPage(int numValues) {
            var ph = new PageHeader {
                Type = PageType.DICTIONARY_PAGE,
                DictionaryPageHeader = new DictionaryPageHeader {
                    Encoding = Encoding.PLAIN_DICTIONARY,
                    NumValues = numValues
                }
            };
            return ph;
        }

        public EncryptionBase? Decrypter => _fileMeta.Decrypter;

        public EncryptionBase? Encrypter { get; set; }

        #region [ Conversion to Model Schema ]

        public ParquetSchema CreateModelSchema(ParquetOptions formatOptions) {
            int si = 0;
            SchemaElement tse = _fileMeta.Schema[si++];
            var container = new List<Field>();

            CreateModelSchema(null, container, tse.NumChildren ?? 0, ref si, formatOptions);

            return new ParquetSchema(container);
        }

        private void CreateModelSchema(FieldPath? path, IList<Field> container, int childCount, ref int si, ParquetOptions formatOptions) {
            for(int i = 0; i < childCount && si < _fileMeta.Schema.Count; i++) {
                Field? se = SchemaEncoder.Decode(_fileMeta.Schema, formatOptions, ref si, out int ownedChildCount);
                if(se == null)
                    throw new InvalidOperationException($"cannot decode schema for field {_fileMeta.Schema[si]}");

                List<string> npath = path?.ToList() ?? new List<string>();
                if(se.Path != null)
                    npath.AddRange(se.Path.ToList());
                else
                    npath.Add(se.Name);
                se.Path = new FieldPath(npath);

                if(ownedChildCount > 0) {
                    var childContainer = new List<Field>();
                    CreateModelSchema(se.Path, childContainer, ownedChildCount, ref si, formatOptions);
                    foreach(Field cse in childContainer) {
                        se.Assign(cse);
                    }
                }

                container.Add(se);
            }
        }

        #endregion

        #region [ Convertion from Model Schema ]

        public FileMetaData CreateThriftSchema(ParquetSchema schema) {
            var meta = new FileMetaData();
            meta.Version = 1;
            meta.Schema = new List<SchemaElement>();
            meta.RowGroups = new List<RowGroup>();

            SchemaElement root = ThriftFooter.AddRoot(meta.Schema);
            foreach(Field se in schema.Fields) {
                SchemaEncoder.Encode(se, root, meta.Schema);
            }

            return meta;
        }


        private static SchemaElement AddRoot(IList<SchemaElement> container) {
            var root = new SchemaElement { Name = "root" };
            container.Add(root);
            return root;
        }

        #endregion

        #region [ Helpers ]

        class ThriftSchemaTree {
            readonly Dictionary<SchemaElement, Node?> _memoizedFindResults =
                new Dictionary<SchemaElement, Node?>(new ReferenceEqualityComparer<SchemaElement>());

            public class Node {
                public SchemaElement? element;
                public List<Node>? children;
                public Node? parent;
            }

            public Node root;

            internal ThriftSchemaTree() {
                root = new Node();
            }

            public ThriftSchemaTree(List<SchemaElement> schema) {
                root = new Node { element = schema[0] };
                int i = 1;

                BuildSchema(root, schema, root.element.NumChildren ?? 0, ref i);
            }

            public Node? Find(SchemaElement tse) {
                if(_memoizedFindResults.TryGetValue(tse, out Node? node)) {
                    return node;
                }
                node = Find(root, tse);
                _memoizedFindResults.Add(tse, node);
                return node;
            }

            private Node? Find(Node root, SchemaElement tse) {
                if(root.children != null) {
                    foreach(Node child in root.children) {
                        if(child.element == tse)
                            return child;

                        if(child.children != null) {
                            Node? cf = Find(child, tse);
                            if(cf != null)
                                return cf;
                        }
                    }
                }

                return null;
            }

            public Node? Find(FieldPath path) {
                if(path.Length == 0)
                    return null;
                return Find(root, path);
            }

            private Node? Find(Node root, FieldPath path) {
                if(root.children != null) {
                    foreach(Node child in root.children) {
                        if(child.element?.Name == path.FirstPart) {
                            if(path.Length == 1)
                                return child;

                            return Find(child, new FieldPath(path.ToList().Skip(1)));
                        }
                    }
                }

                return null;
            }

            private void BuildSchema(Node parent, List<SchemaElement> schema, int count, ref int i) {
                parent.children = new List<Node>();
                for(int ic = 0; ic < count; ic++) {
                    SchemaElement child = schema[i++];
                    var node = new Node { element = child, parent = parent };
                    parent.children.Add(node);
                    if(child.NumChildren > 0) {
                        BuildSchema(node, schema, child.NumChildren ?? 0, ref i);
                    }
                }
            }
        }

        public void SetPlaintextFooterAlgorithm(Meta.EncryptionAlgorithm alg) {
            if(alg == null)
                throw new ArgumentNullException(nameof(alg));
            _fileMeta.EncryptionAlgorithm = alg;
        }

        public void SetFooterSigningKeyMetadata(byte[]? metadata) {
            _fileMeta.FooterSigningKeyMetadata = metadata;
        }

        #endregion
    }
}

using System;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Security.Cryptography;
using System.Text;
using System.Threading;
using System.Threading.Tasks;
using Parquet.Encryption;
using Parquet.Extensions;

namespace Parquet {
    /// <summary>
    /// Base class for reader and writer
    /// </summary>
    public class ParquetActor {
#pragma warning disable IDE1006
        internal static readonly byte[] MagicBytes = Encoding.ASCII.GetBytes("PAR1");
        internal static readonly byte[] MagicBytesEncrypted = Encoding.ASCII.GetBytes("PARE");
#pragma warning restore IDE1006

        private readonly Stream _fileStream;

        private BinaryWriter? _binaryWriter;

        internal ParquetActor(Stream? fileStream) =>
            _fileStream = fileStream ?? throw new ArgumentNullException(nameof(fileStream));

        /// <summary>
        /// Original stream to write or read
        /// </summary>
        protected Stream Stream => _fileStream;

        internal bool IsEncryptedFile;

        internal BinaryWriter Writer => _binaryWriter ??= new BinaryWriter(_fileStream);

        /// <summary>
        /// Validates that this file is a valid parquet file by reading head and tail of it
        /// </summary>
        /// <returns></returns>
        /// <exception cref="IOException"></exception>
        public async Task ValidateFileAsync() {
            _fileStream.Seek(0, SeekOrigin.Begin);
            byte[] head = await _fileStream.ReadBytesExactlyAsync(4);

            _fileStream.Seek(-4, SeekOrigin.End);
            byte[] tail = await _fileStream.ReadBytesExactlyAsync(4);

            if(!MagicBytes.SequenceEqual(head) || !MagicBytes.SequenceEqual(tail)) {
                if(!MagicBytesEncrypted.SequenceEqual(head) || !MagicBytesEncrypted.SequenceEqual(tail)) {
                    throw new IOException($"not a parquet file, head: {head.ToHexString()}, tail: {tail.ToHexString()}");
                }
                IsEncryptedFile = true;
            }
        }

        internal async ValueTask<Meta.FileMetaData> ReadMetadataAsync(
            string? footerEncryptionKey = null,
            string? footerSigningKey = null,
            string? aadPrefix = null
        ) {
            // Move to tail and read the whole footer payload:
            int tailLen = await GoBeforeFooterAsync();
            byte[] tail = await Stream.ReadBytesExactlyAsync(tailLen);

            using var ms = new MemoryStream(tail, writable: false);
            var proto = new Parquet.Meta.Proto.ThriftCompactProtocolReader(ms);

            // -----------------------------
            // ENCRYPTED-FOOTER MODE (PARE)
            // -----------------------------
            if(IsEncryptedFile) {
                if(string.IsNullOrWhiteSpace(footerEncryptionKey)) {
                    throw new InvalidDataException($"{nameof(ParquetOptions.FooterEncryptionKey)} is required for files with encrypted footers.");
                }

                // Tail = FileCryptoMetaData || EncryptedFooterModule
                var decr = Encryption.EncryptionBase.CreateFromCryptoMeta(proto, footerEncryptionKey!, aadPrefix);
                byte[] plainFooter = decr.DecryptFooter(proto);

                using var fms = new MemoryStream(plainFooter, writable: false);
                var fpr = new Parquet.Meta.Proto.ThriftCompactProtocolReader(fms);
                var meta = Meta.FileMetaData.Read(fpr);
                meta.Decrypter = decr;           // needed so page/index readers decrypt modules
                return meta;
            }

            // ------------------------------------------
            // PLAINTEXT FOOTER (optionally signed §5.5)
            // Tail is either:
            //   [footer][len][PAR1]  (legacy, but in our "tail" we only have 'footer')
            //   or
            //   [footer][nonce(12)|tag(16)]  (we only see footer+28 here; the [len][PAR1] was stripped earlier)
            // ------------------------------------------

            // Try "signed plaintext footer" first if at least 28 bytes are available for nonce+tag.
            if(tailLen >= 28) {
                int footerLen = tailLen - 28;

                Meta.FileMetaData? metaSigned = null;
                try {
                    using var fmsProbe = new MemoryStream(tail, 0, footerLen, writable: false);
                    var rProbe = new Parquet.Meta.Proto.ThriftCompactProtocolReader(fmsProbe);
                    metaSigned = Meta.FileMetaData.Read(rProbe);
                } catch {
                    metaSigned = null; // couldn't parse — treat as legacy below
                }

                // Per spec, plaintext-footer-with-signature stores EncryptionAlgorithm in FileMetaData.
                if(metaSigned is not null && metaSigned.EncryptionAlgorithm is not null) {
                    Meta.EncryptionAlgorithm alg = metaSigned.EncryptionAlgorithm;
                    byte[] aadFileUnique;
                    bool requirePrefix;
                    byte[] aadPrefixBytes;

                    if(alg.AESGCMV1 is not null) {
                        aadFileUnique = alg.AESGCMV1.AadFileUnique ?? Array.Empty<byte>();
                        requirePrefix = alg.AESGCMV1.SupplyAadPrefix == true;
                        aadPrefixBytes = requirePrefix
                            ? (!string.IsNullOrEmpty(aadPrefix)
                                ? System.Text.Encoding.ASCII.GetBytes(aadPrefix!)
                                : throw new InvalidDataException("This file requires an AAD prefix to verify the footer signature."))
                            : (alg.AESGCMV1.AadPrefix ?? Array.Empty<byte>());
                    } else if(alg.AESGCMCTRV1 is not null) {
                        aadFileUnique = alg.AESGCMCTRV1.AadFileUnique ?? Array.Empty<byte>();
                        requirePrefix = alg.AESGCMCTRV1.SupplyAadPrefix == true;
                        aadPrefixBytes = requirePrefix
                            ? (!string.IsNullOrEmpty(aadPrefix)
                                ? System.Text.Encoding.ASCII.GetBytes(aadPrefix!)
                                : throw new InvalidDataException("This file requires an AAD prefix to verify the footer signature."))
                            : (alg.AESGCMCTRV1.AadPrefix ?? Array.Empty<byte>());
                    } else {
                        throw new InvalidDataException("Unsupported encryption algorithm for signed plaintext footer.");
                    }

                    // Pick signer to match the file’s algorithm (GCM vs GCM-CTR)
                    Encryption.EncryptionBase signer =
                        (alg.AESGCMV1 is not null)
                            ? new AES_GCM_V1_Encryption()
                            : new AES_GCM_CTR_V1_Encryption();

                    signer.AadFileUnique = aadFileUnique;
                    signer.AadPrefix = aadPrefixBytes;

                    if(string.IsNullOrWhiteSpace(footerSigningKey))
                        throw new InvalidDataException($"{nameof(ParquetOptions.FooterSigningKey)} is required to verify a signed plaintext footer.");

                    // Build AAD for the Footer module using the right variant
                    byte[] aad = signer.BuildAad(Meta.ParquetModules.Footer);

                    // Key to verify signature (same as parquet-mr footer key)
                    byte[] key = Encryption.EncryptionBase.ParseKeyString(footerSigningKey!);

                    // Stored values
                    byte[] footerBytes = tail.AsSpan(0, footerLen).ToArray();
                    byte[] nonce = new byte[12];
                    byte[] storedTag = new byte[16];
                    Buffer.BlockCopy(tail, footerLen + 0, nonce, 0, 12);
                    Buffer.BlockCopy(tail, footerLen + 12, storedTag, 0, 16);

                    // First try: “encrypt-then-tag” (footer as plaintext)
                    byte[] calcTag = new byte[16];
                    byte[] tmpCt = new byte[footerLen]; // ciphertext thrown away
                    CryptoHelpers.GcmEncryptOrThrow(key, nonce, footerBytes, tmpCt, calcTag, aad);

                    bool ok = CryptoHelpers.FixedTimeEquals(calcTag, storedTag);
                    EncTrace.VerifyAttempt("PF-Footer", "encrypt-then-tag", nonce, storedTag, ok);

                    if(!ok) {
                        // Second try: “AAD-only” tag (empty plaintext, AAD = parquetAAD || footer)
                        // i.e., authenticate footer bytes as part of AAD, with zero-length plaintext.
                        byte[] aad2 = new byte[aad.Length + footerBytes.Length];
                        Buffer.BlockCopy(aad, 0, aad2, 0, aad.Length);
                        Buffer.BlockCopy(footerBytes, 0, aad2, aad.Length, footerBytes.Length);

                        byte[] calcTag2 = new byte[16];
                        VerifyPlaintextFooterSignature(tail, key, nonce, calcTag2, aad2);

                        ok = CryptoHelpers.FixedTimeEquals(calcTag2, storedTag);
                        EncTrace.VerifyAttempt("PF-Footer", "AAD-only", nonce, storedTag, ok);
                    }
                    EncTrace.FooterMode("ReadMetadata", "PLAINTEXT_FOOTER");

                    if(!ok)
                        throw new InvalidDataException("Footer signature verification failed.");

                    // Success — hook up a decrypter if the file advertises encryption (PF mode)
                    if(metaSigned.EncryptionAlgorithm is not null) {
                        if(string.IsNullOrWhiteSpace(footerEncryptionKey))
                            throw new InvalidDataException($"{nameof(ParquetOptions.FooterEncryptionKey)} is required to read encrypted columns in plaintext-footer files.");

                        metaSigned.Decrypter = EncryptionBase.CreateFromAlgorithm(
                            metaSigned.EncryptionAlgorithm,
                            footerEncryptionKey!,
                            aadPrefix
                        );
                    } else {
                        metaSigned.Decrypter = null;
                    }

                    return metaSigned;
                }
            }

            // Legacy plaintext (no signature / no algorithm in footer)
            {
                using var fms = new MemoryStream(tail, writable: false);
                var fpr = new Parquet.Meta.Proto.ThriftCompactProtocolReader(fms);
                var meta = Meta.FileMetaData.Read(fpr);
                meta.Decrypter = null;
                return meta;
            }
        }

        internal async ValueTask<int> GoBeforeFooterAsync() {
            //go to -4 bytes (PAR1) -4 bytes (footer length number)
            _fileStream.Seek(-8, SeekOrigin.End);
            int footerLength = await _fileStream.ReadInt32Async();

            //set just before footer starts
            _fileStream.Seek(-8 - footerLength, SeekOrigin.End);

            return footerLength;
        }

        // inside ParquetActor
        internal static void VerifyPlaintextFooterSignature(
            ReadOnlySpan<byte> footerBytes,
            ReadOnlySpan<byte> key,
            ReadOnlySpan<byte> nonce12,
            ReadOnlySpan<byte> storedTag16,
            ReadOnlySpan<byte> moduleAad) {
            // We only need to reproduce the tag; ciphertext is ignored.
            Span<byte> tmpCt = footerBytes.Length == 0 ? Span<byte>.Empty : new byte[footerBytes.Length];
            Span<byte> calcTag = stackalloc byte[16];

            CryptoHelpers.GcmEncryptOrThrow(
                key: key.ToArray(),
                nonce: nonce12,
                plaintext: footerBytes,
                ciphertext: tmpCt,
                tag: calcTag,
                aad: moduleAad
            );

            if(!CryptoHelpers.FixedTimeEquals(calcTag, storedTag16))
                throw new InvalidDataException("Footer signature verification failed.");
        }
    }
}

using System;
using System.Collections.Generic;
using System.Data;

namespace Parquet {
    /// <summary>
    /// Parquet options
    /// </summary>
    public class ParquetOptions {

        /// <summary>
        /// When true byte arrays will be treated as UTF-8 strings on read
        /// </summary>
        public bool TreatByteArrayAsString { get; set; } = false;

        /// <summary>
        /// Gets or sets a value indicating whether big integers are always treated as dates on read
        /// </summary>
        public bool TreatBigIntegersAsDates { get; set; } = true;

#if NET6_0_OR_GREATER
        /// <summary>
        /// When set to true, parquet dates will be deserialized as <see cref="DateOnly"/>, otherwise
        /// as <see cref="DateTime"/> with missing time part.
        /// </summary>
        public bool UseDateOnlyTypeForDates { get; set; } = false;

        /// <summary>
        /// When set to true, parquet times with millisecond precision will be deserialized as <see cref="TimeOnly"/>, otherwise
        /// as <see cref="TimeSpan"/> with missing time part.
        /// </summary>
        public bool UseTimeOnlyTypeForTimeMillis { get; set; } = false;

        /// <summary>
        /// When set to true, parquet times with microsecond precision will be deserialized as <see cref="TimeOnly"/>, otherwise
        /// as <see cref="TimeSpan"/> with missing time part.
        /// </summary>
        public bool UseTimeOnlyTypeForTimeMicros { get; set; } = false;
#endif

        /// <summary>
        /// Whether to use dictionary encoding for columns if data meets <seealso cref="DictionaryEncodingThreshold"/>
        /// The following CLR types are currently supported:
        /// <see cref="string"/>, <see cref="DateTime"/>, <see cref="decimal"/>, <see cref="byte"/>, <see cref="short"/>, <see cref="ushort"/>, <see cref="int"/>, <see cref="uint"/>, <see cref="long"/>, <see cref="ulong"/>, <see cref="float"/>, <see cref="double"/>"/>
        /// </summary>
        public bool UseDictionaryEncoding { get; set; } = true;

        /// <summary>
        /// Dictionary uniqueness threshold, which is a value from 0 (no unique values) 
        /// to 1 (all values are unique) indicating when dictionary encoding is applied.
        /// Uniqueness factor needs to be less or equal than this threshold.
        /// </summary>
        public double DictionaryEncodingThreshold { get; set; } = 0.8;

        /// <summary>
        /// When set, the default encoding for INT32 and INT64 is <see cref="Parquet.Meta.Encoding.DELTA_BINARY_PACKED"/>, otherwise
        /// it's reverted to <see cref="Parquet.Meta.Encoding.PLAIN"/>. You should only set this to <see langword="false"/> if
        /// your readers do not understand it.
        /// </summary>
        public bool UseDeltaBinaryPackedEncoding { get; set; } = true;

        /// <summary>
        /// This option is passed to the <see cref="Microsoft.IO.RecyclableMemoryStreamManager"/> , 
        /// which keeps a pool of streams in memory for reuse. 
        /// By default when this option is unset, the RecyclableStreamManager 
        /// will keep an unbounded amount of memory, which is 
        /// "indistinguishable from a memory leak" per their documentation.
        /// 
        /// This does not restrict the size of the pool, but just allows 
        /// the garbage collector to free unused memory over this limit.
        /// 
        /// You may want to adjust this smaller to reduce max memory usage, 
        /// or larger to reduce garbage collection frequency.
        /// 
        /// Defaults to 16MB.  
        /// </summary>
        public int MaximumSmallPoolFreeBytes { get; set; } = 16 * 1024 * 1024;

        /// <summary>
        /// This option is passed to the <see cref="Microsoft.IO.RecyclableMemoryStreamManager"/> , 
        /// which keeps a pool of streams in memory for reuse. 
        /// By default when this option is unset, the RecyclableStreamManager 
        /// will keep an unbounded amount of memory, which is 
        /// "indistinguishable from a memory leak" per their documentation.
        /// 
        /// This does not restrict the size of the pool, but just allows 
        /// the garbage collector to free unused memory over this limit.
        /// 
        /// You may want to adjust this smaller to reduce max memory usage, 
        /// or larger to reduce garbage collection frequency.
        /// 
        /// Defaults to 64MB.
        /// </summary>
        public int MaximumLargePoolFreeBytes { get; set; } = 64 * 1024 * 1024;

        #region modular encryption

        /// <summary>
        /// Write files using plaintext footer mode (§5.5). Footer is signed (GCM) not encrypted.
        /// Magic stays PAR1 for legacy readers.
        /// </summary>
        public bool UsePlaintextFooter { get; set; } = false;

        /// <summary>
        /// Footer key for encrypted footer mode (PARE). If null and UsePlaintextFooter==true,
        /// footer is plaintext (optionally signed).
        /// </summary>
        public string? FooterEncryptionKey { get; set; }

        /// <summary>
        /// Gets or sets the key used to sign the footer when using plaintext footer mode.
        /// </summary>
        public string? FooterSigningKey { get; set; } = null;

        /// <summary>
        /// Optional Additional Authentication Data Prefix used to verify the integrity of the encrypted file. Only required
        /// if the file was encrypted with an AAD Prefix *and* the prefix wasn't embedded into the 
        /// file by the author.
        /// </summary>
        /// <remarks>Currently only used by <see cref="ParquetReader"/></remarks>
        public string? AADPrefix { get; set; } = null;

        /// <summary>
        /// Controls whether the writer embeds the AAD prefix in the file metadata
        /// or requires readers to supply it out-of-band.
        /// </summary>
        /// <value>
        /// <c>false</c> (default): store the AAD prefix in the file (if provided in <see cref="AADPrefix"/>).<br/>
        /// <c>true</c>: do not store the prefix; readers must provide the same prefix to decrypt.
        /// </value>
        /// <remarks>
        /// <para>
        /// When <c>true</c>, <see cref="AADPrefix"/> must be set at write time. During read, the same prefix
        /// must be provided in <see cref="AADPrefix"/>; otherwise decryption fails with an explicit error.
        /// </para>
        /// <para>
        /// This maps to the Parquet encryption algorithm field <c>supply_aad_prefix</c>.
        /// </para>
        /// </remarks>
        public bool SupplyAadPrefix { get; set; } = false;

        /// <summary>
        /// Use the AES-GCM-CTR variant for page bodies (per Parquet modular encryption spec).
        /// </summary>
        /// <value>
        /// <c>false</c> (default): all modules use AES-GCM (V1).<br/>
        /// <c>true</c>: page <b>bodies</b> use AES-CTR framing; page headers and all other modules remain AES-GCM.
        /// </value>
        /// <remarks>
        /// <para>
        /// Regardless of this setting, the file <b>footer</b> is always encrypted with AES-GCM.
        /// </para>
        /// <para>
        /// Set this only if you need interoperability with writers/readers expecting the AES_GCM_CTR_V1 profile.
        /// </para>
        /// </remarks>
        public bool UseCtrVariant { get; set; } = false;

        // ParquetOptions.cs

        /// <summary>
        /// Specifies a column encryption key and optional key metadata for Parquet modular encryption.
        /// </summary>
        /// <param name="Key">The encryption key as a string.</param>
        /// <param name="KeyMetadata">Optional key metadata as a byte array.</param>
        public sealed record ColumnKeySpec(string Key, byte[]? KeyMetadata = null);

        /// <summary>
        /// Column keys to use when writing. Keyed by full path (e.g. "root.col" or just "col"
        /// depending on how you form PathInSchema in your code).
        /// If a column is present here, all of its modules (pages, page headers, indexes, bloom)
        /// will be encrypted with this key, and its ColumnMetaData will be serialized
        /// separately and encrypted into ColumnChunk.encrypted_column_metadata.
        /// </summary>
        public Dictionary<string, ColumnKeySpec> ColumnKeys { get; } =
            new(StringComparer.Ordinal);

        /// <summary>
        /// Reader-side resolver that returns the AES key for a column given its path_in_schema
        /// and key_metadata from ColumnCryptoMetaData.ENCRYPTION_WITH_COLUMN_KEY.
        /// Return null to indicate key is unavailable (will throw when trying to read the column).
        /// </summary>
        public Func<IReadOnlyList<string>, byte[]?, string?>? ColumnKeyResolver { get; set; }

        #endregion modular encryption
    }
}

using Parquet.File;
using System;
using System.Collections.Generic;
using System.IO;
using Parquet.Data;
using System.Threading.Tasks;
using System.Threading;
using Parquet.Schema;
using Parquet.Meta;

namespace Parquet {
    /// <summary>
    /// Implements Apache Parquet format reader, experimental version for next major release.
    /// </summary>
    public class ParquetReader : ParquetActor, IDisposable {
        private readonly Stream _input;
        private FileMetaData? _meta;
        private ThriftFooter _thriftFooter;
        private readonly ParquetOptions _parquetOptions;
        private readonly List<ParquetRowGroupReader> _groupReaders = new();
        private readonly bool _leaveStreamOpen;

        private ParquetReader(Stream input, ParquetOptions? parquetOptions = null, bool leaveStreamOpen = true) : base(input) {
            _input = input ?? throw new ArgumentNullException(nameof(input));
            _leaveStreamOpen = leaveStreamOpen;

            if(!input.CanRead || !input.CanSeek)
                throw new ArgumentException("stream must be readable and seekable", nameof(input));
            if(_input.Length <= 8)
                throw new IOException("not a Parquet file (size too small)");

            _parquetOptions = parquetOptions ?? new ParquetOptions();

            // _fThriftFooter will be initialised right now in the InitialiseAsync
            _thriftFooter = ThriftFooter.Empty;
        }

        private async Task InitialiseAsync(CancellationToken cancellationToken) {
            await ValidateFileAsync().ConfigureAwait(false);

            // Let ReadMetadataAsync decide what’s required based on the file
            _meta = await ReadMetadataAsync(
                footerEncryptionKey: _parquetOptions.FooterEncryptionKey,
                footerSigningKey: _parquetOptions.FooterSigningKey,
                aadPrefix: _parquetOptions.AADPrefix
            ).ConfigureAwait(false);

            _thriftFooter = new ThriftFooter(_meta);

            InitRowGroupReaders();
        }

        /// <summary>
        /// Opens reader from a file on disk. When the reader is disposed the file handle is automatically closed.
        /// </summary>
        /// <param name="filePath"></param>
        /// <param name="parquetOptions"></param>
        /// <param name="cancellationToken"></param>
        /// <returns></returns>
        public static async Task<ParquetReader> CreateAsync(string filePath,
            ParquetOptions? parquetOptions = null,
            CancellationToken cancellationToken = default) {
            Stream fs = System.IO.File.OpenRead(filePath);
            var reader = new ParquetReader(fs, parquetOptions, false);
            await reader.InitialiseAsync(cancellationToken);
            return reader;
        }

        /// <summary>
        /// Creates an instance from input stream
        /// </summary>
        /// <param name="input">Input stream, must be readable and seekable</param>
        /// <param name="parquetOptions">Optional reader options</param>
        /// <param name="leaveStreamOpen">When true, leaves the stream passed in <paramref name="input"/> open after disposing the reader.</param>
        /// <param name="cancellationToken"></param>
        /// <exception cref="ArgumentNullException">input</exception>
        /// <exception cref="ArgumentException">stream must be readable and seekable - input</exception>
        /// <exception cref="IOException">not a Parquet file (size too small)</exception>
        public static async Task<ParquetReader> CreateAsync(
            Stream input, ParquetOptions? parquetOptions = null, bool leaveStreamOpen = true,
            CancellationToken cancellationToken = default) {

            var reader = new ParquetReader(input, parquetOptions, leaveStreamOpen);
            await reader.InitialiseAsync(cancellationToken);
            return reader;
        }

        /// <summary>
        /// Gets custom key-value pairs for metadata
        /// </summary>
        public Dictionary<string, string> CustomMetadata => _thriftFooter.CustomMetadata;


        #region [ Helpers ]

        /// <summary>
        /// Opens file at specified path to read schema and return
        /// </summary>
        public static async Task<ParquetSchema> ReadSchemaAsync(string filePath) {
            using ParquetReader reader = await CreateAsync(filePath);
            return reader.Schema;
        }

        /// <summary>
        /// Reads file stream and returns
        /// </summary>
        public static async Task<ParquetSchema> ReadSchemaAsync(Stream parquetStream) {
            using ParquetReader reader = await CreateAsync(parquetStream);
            return reader.Schema;
        }

        #endregion

        /// <summary>
        /// Gets the number of rows groups in this file
        /// </summary>
        public int RowGroupCount => _meta?.RowGroups.Count ?? -1;

        /// <summary>
        /// Reader schema
        /// </summary>
        public ParquetSchema Schema => _thriftFooter!.CreateModelSchema(_parquetOptions);

        /// <summary>
        /// Internal parquet metadata
        /// </summary>
        public FileMetaData? Metadata => _meta;

        /// <summary>
        /// Opens row group reader. Note that this operation is really cheap as all the metadata is already present.
        /// It only gets expensive when you read actual data, not the metadata itself.
        /// </summary>
        /// <param name="index">Row group index, starting from 0. See <see cref="RowGroupCount"/> to get number of row groups in this file.</param>
        /// <returns></returns>
        public ParquetRowGroupReader OpenRowGroupReader(int index) {
            return _groupReaders[index];
        }

        /// <summary>
        /// Collection of row group readers, fast random access and enumeration
        /// </summary>
        public IReadOnlyList<IParquetRowGroupReader> RowGroups => _groupReaders;

        /// <summary>
        /// Reads entire row group's data columns in one go.
        /// </summary>
        /// <param name="rowGroupIndex">Index of the row group. Default to the first row group if not specified.</param>
        /// <returns></returns>
        public async Task<DataColumn[]> ReadEntireRowGroupAsync(int rowGroupIndex = 0) {
            if(Schema == null)
                throw new InvalidOperationException("schema is not initialised yet");

            DataField[] dataFields = Schema.GetDataFields();
            DataColumn[] result = new DataColumn[dataFields.Length];

            using(ParquetRowGroupReader reader = OpenRowGroupReader(rowGroupIndex)) {
                for(int i = 0; i < dataFields.Length; i++) {
                    DataColumn column = await reader.ReadColumnAsync(dataFields[i]);
                    result[i] = column;
                }
            }

            return result;
        }

        private void InitRowGroupReaders() {
            _groupReaders.Clear();
            if(_meta?.RowGroups == null)
                throw new InvalidOperationException("no row groups in metadata");

            foreach(RowGroup rowGroup in _meta.RowGroups) {
                _groupReaders.Add(new ParquetRowGroupReader(rowGroup, _thriftFooter!, Stream, _parquetOptions));
            }
        }

        /// <summary>
        /// <inheritdoc/>
        /// </summary>
        public void Dispose() {
            if(!_leaveStreamOpen) {
                _input.Dispose();
            }
        }
    }
}

using System;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;
using Parquet.Data;
using Parquet.Encodings;
using Parquet.Encryption;
using Parquet.File;
using Parquet.Meta;
using Parquet.Meta.Proto;
using Parquet.Schema;

namespace Parquet {
    /// <summary>
    /// Operations available on a row group reader, omitting Dispose, which is 
    /// exposed on the implementing class for backward compatibility only.
    /// </summary>
    public interface IParquetRowGroupReader {
        /// <summary>
        /// Exposes raw metadata about this row group
        /// </summary>
        RowGroup RowGroup { get; }

        /// <summary>
        /// Gets the number of rows in this row group
        /// </summary>
        long RowCount { get; }

        /// <summary>
        /// Checks if this field exists in source schema
        /// </summary>
        bool ColumnExists(DataField field);

        /// <summary>
        /// Reads a column from this row group. Unlike writing, columns can be read in any order.
        /// If the column is missing, an exception will be thrown.
        /// </summary>
        Task<DataColumn> ReadColumnAsync(DataField field, CancellationToken cancellationToken = default);

        /// <summary>
        /// Gets raw column chunk metadata for this field
        /// </summary>
        ColumnChunk? GetMetadata(DataField field);

        /// <summary>
        /// Get custom key-value metadata for a data field
        /// </summary>
        Dictionary<string, string> GetCustomMetadata(DataField field);

        /// <summary>
        /// Returns data column statistics for a particular data field
        /// </summary>
        /// <param name="field"></param>
        /// <returns></returns>
        /// <exception cref="ParquetException"></exception>
        DataColumnStatistics? GetStatistics(DataField field);
    }

    /// <summary>
    /// Reader for Parquet row groups
    /// </summary>
    public class ParquetRowGroupReader : IDisposable, IParquetRowGroupReader {
        private readonly RowGroup _rowGroup;
        private readonly ThriftFooter _footer;
        private readonly Stream _stream;
        private readonly ParquetOptions? _options;
        private readonly Dictionary<FieldPath, ColumnChunk> _pathToChunk = new();
        private readonly List<(short colOrd, ColumnChunk cc)> _encryptedColumnChunks = new();

        internal ParquetRowGroupReader(
           RowGroup rowGroup,
           ThriftFooter footer,
           Stream stream,
           ParquetOptions? parquetOptions) {
            _rowGroup = rowGroup ?? throw new ArgumentNullException(nameof(rowGroup));
            _footer = footer ?? throw new ArgumentNullException(nameof(footer));
            _stream = stream ?? throw new ArgumentNullException(nameof(stream));
            _options = parquetOptions ?? throw new ArgumentNullException(nameof(parquetOptions));

            //cache chunks
            for(int colIdx = 0; colIdx < rowGroup.Columns.Count; colIdx++) {
                ColumnChunk cc = rowGroup.Columns[colIdx];

                // Case 1: Plain metadata present -> register immediately
                if(cc.MetaData != null) {
                    FieldPath path = _footer.GetPath(cc);
                    _pathToChunk[path] = cc;
                    continue;
                }

                // Case 2: Metadata is encrypted -> DO NOT fail here.
                // We may still be able to read plaintext columns in this file without column keys.
                if(cc.EncryptedColumnMetadata != null) {
                    _encryptedColumnChunks ??= new List<(short colOrd, ColumnChunk cc)>();
                    short colOrd = (short)colIdx;
                    _encryptedColumnChunks.Add((colOrd, cc));
                    // We’ll resolve (decrypt or throw) lazily if the caller asks for this column.
                    continue;
                }
                // Truly malformed chunk (neither MetaData nor EncryptedColumnMetadata)
                throw new InvalidDataException("ColumnChunk is missing both MetaData and EncryptedColumnMetadata.");
            }
        }

        /// <summary>
        /// Exposes raw metadata about this row group
        /// </summary>
        public RowGroup RowGroup => _rowGroup;

        /// <summary>
        /// Gets the number of rows in this row group
        /// </summary>
        public long RowCount => _rowGroup.NumRows;

        /// <summary>
        /// Checks if this field exists in source schema
        /// </summary>
        public bool ColumnExists(DataField field) => GetMetadata(field) != null;


        /// <summary>
        /// Reads a column from this row group. Unlike writing, columns can be read in any order.
        /// If the column is missing, an exception will be thrown.
        /// </summary>
        public Task<DataColumn> ReadColumnAsync(DataField field, CancellationToken cancellationToken = default) {
            ColumnChunk columnChunk = GetMetadata(field)
                ?? throw new ParquetException($"'{field.Path}' does not exist in this file");
            var columnReader = new DataColumnReader(field, _stream,
                columnChunk, ReadColumnStatistics(columnChunk), _footer, _options, _rowGroup);
            return columnReader.ReadAsync(cancellationToken);
        }

        /// <summary>
        /// Gets raw column chunk metadata for this field
        /// </summary>
        public ColumnChunk? GetMetadata(DataField field) {
            if(field == null)
                throw new ArgumentNullException(nameof(field));
            return ResolveChunkFor(field.Path);
        }


        /// <summary>
        /// Get custom key-value metadata for a data field
        /// </summary>
        public Dictionary<string, string> GetCustomMetadata(DataField field) {
            ColumnChunk? cc = GetMetadata(field);
            if(cc?.MetaData?.KeyValueMetadata == null)
                return new();

            return cc.MetaData.KeyValueMetadata.ToDictionary(kv => kv.Key, kv => kv.Value!);
        }

        private DataColumnStatistics? ReadColumnStatistics(ColumnChunk cc) {
            Statistics? st = cc.MetaData?.Statistics;

            if((st == null || (st.MinValue == null && st.MaxValue == null && st.NullCount == null)) &&
                cc.EncryptedColumnMetadata != null &&
                cc.CryptoMetadata?.ENCRYPTIONWITHCOLUMNKEY != null) {
                // Find path and column ordinal
                FieldPath path = _footer.GetPath(cc);
                short rgOrd = _footer.GetRowGroupOrdinal(_rowGroup);
                short colOrd = (short)_rowGroup.Columns.IndexOf(cc);

                // Resolve (will decrypt and cache MetaData)
                ColumnChunk? resolved = ResolveChunkFor(path);
                if(resolved?.MetaData?.Statistics != null)
                    st = resolved.MetaData.Statistics;
            }

            if(st == null)
                return null;

            SchemaElement? se = _footer.GetSchemaElement(cc)
                ?? throw new ArgumentException("can't find schema element", nameof(cc));

            ParquetPlainEncoder.TryDecode(st.MinValue, se, _options!, out object? min);
            ParquetPlainEncoder.TryDecode(st.MaxValue, se, _options!, out object? max);

            return new DataColumnStatistics(st.NullCount, st.DistinctCount, min, max);
        }



        /// <summary>
        /// Returns data column statistics for a particular data field
        /// </summary>
        /// <param name="field"></param>
        /// <returns></returns>
        /// <exception cref="ParquetException"></exception>
        public DataColumnStatistics? GetStatistics(DataField field) {
            ColumnChunk cc = GetMetadata(field) ?? throw new ParquetException($"'{field.Path}' does not exist in this file");
            return ReadColumnStatistics(cc);
        }

        private ColumnChunk? ResolveChunkFor(FieldPath path) {
            if(_pathToChunk.TryGetValue(path, out ColumnChunk? ccPlain))
                return ccPlain;

            // Try find a matching encrypted chunk by path; if found, decrypt and cache
            for(int i = 0; i < _encryptedColumnChunks.Count; i++) {
                (short colOrd, ColumnChunk? encCc) = _encryptedColumnChunks[i];
                FieldPath encPath = _footer.GetPath(encCc);
                if(!encPath.Equals(path))
                    continue;

                DecryptColumnMetaFor(encCc, encPath, colOrd);
                return encCc; // MetaData now populated & cached
            }

            return null;
        }

        private void DecryptColumnMetaFor(ColumnChunk encCc, FieldPath path, short colOrd) {
            // Column-key info is required on encrypted column meta
            EncryptionWithColumnKey ck = encCc.CryptoMetadata?.ENCRYPTIONWITHCOLUMNKEY
                     ?? throw new NotSupportedException(
                         $"Column '{path}' has encrypted metadata but lacks column-key crypto metadata.");

            string? keyString = _options?.ColumnKeyResolver?.Invoke(ck.PathInSchema, ck.KeyMetadata);
            if(string.IsNullOrWhiteSpace(keyString))
                throw new NotSupportedException(
                    $"Column '{path}' uses column-key encryption. Provide a ColumnKeyResolver in ParquetOptions to supply the key.");

            byte[] columnKey = EncryptionBase.ParseKeyString(keyString!);

            // We need AAD context (prefix + fileUnique) from the file
            EncryptionBase? ctx = _footer.Decrypter ?? _footer.Encrypter;
            if(ctx == null)
                throw new NotSupportedException($"Column '{path}' metadata is encrypted and AAD context is unavailable.");

            // Create a fresh decrypter with the same algorithm, copy AAD, set the column key
            EncryptionBase dec = ctx is AES_GCM_CTR_V1_Encryption
                ? new AES_GCM_CTR_V1_Encryption()
                : new AES_GCM_V1_Encryption();

            dec.AadPrefix = ctx.AadPrefix;
            dec.AadFileUnique = ctx.AadFileUnique;
            dec.FooterEncryptionKey = columnKey;

            // Decrypt ColumnMetaData (needs row-group & column ordinals)
            using var msEnc = new MemoryStream(encCc.EncryptedColumnMetadata!);
            var tpr = new Parquet.Meta.Proto.ThriftCompactProtocolReader(msEnc);

            short rgOrd = _footer.GetRowGroupOrdinal(_rowGroup);     // <-- use your ThriftFooter helper
            byte[] plain = dec.DecryptColumnMetaData(tpr, rgOrd, colOrd);

            using var ms = new MemoryStream(plain);
            var r = new Parquet.Meta.Proto.ThriftCompactProtocolReader(ms);
            ColumnMetaData realMeta = Meta.ColumnMetaData.Read(r);

            encCc.MetaData = realMeta;            // cache the real meta
            _pathToChunk[path] = encCc;         // make lookups fast next time
        }

        /// <summary>
        /// Dispose isn't required, retained for backward compatibility
        /// </summary>
        public void Dispose() { }
    }
}

using System;
using System.Collections.Generic;
using System.IO;
using System.IO.Compression;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;
using Parquet.Schema;
using Parquet.File;
using Parquet.Meta;
using Parquet.Extensions;
using Parquet.Encryption;
using System.Security.Cryptography;

namespace Parquet {
    /// <summary>
    /// Implements Apache Parquet format writer
    /// </summary>
    public sealed class ParquetWriter : ParquetActor, IDisposable, IAsyncDisposable {
        private ThriftFooter? _footer;
        private readonly ParquetSchema _schema;
        private readonly ParquetOptions _formatOptions;
        private bool _dataWritten;
        private readonly List<ParquetRowGroupWriter> _openedWriters = new List<ParquetRowGroupWriter>();
        private EncryptionBase? _encrypter;
        private Meta.FileCryptoMetaData? _cryptoMeta;

        // for plaintext-footer mode
        private Meta.EncryptionAlgorithm? _plaintextAlg;

        // holds AadPrefix/AadFileUnique to build AAD for signing
        private EncryptionBase? _signer;

        /// <summary>
        /// Type of compression to use, defaults to <see cref="CompressionMethod.Snappy"/>
        /// </summary>
        public CompressionMethod CompressionMethod { get; set; } = CompressionMethod.Snappy;

        /// <summary>
        /// Level of compression
        /// </summary>
#if NET6_0_OR_GREATER
        public CompressionLevel CompressionLevel = CompressionLevel.SmallestSize;
#else
        public CompressionLevel CompressionLevel = CompressionLevel.Optimal;
#endif

        private ParquetWriter(ParquetSchema schema, Stream output, ParquetOptions? formatOptions = null, bool append = false)
           : base(output.CanSeek == true ? output : new MeteredWriteStream(output)) {
            if(output == null)
                throw new ArgumentNullException(nameof(output));

            if(!output.CanWrite)
                throw new ArgumentException("stream is not writeable", nameof(output));
            _schema = schema ?? throw new ArgumentNullException(nameof(schema));
            _formatOptions = formatOptions ?? new ParquetOptions();
        }

        /// <summary>
        /// Creates an instance of parquet writer on top of a stream
        /// </summary>
        /// <param name="schema"></param>
        /// <param name="output">Writeable, seekable stream</param>
        /// <param name="formatOptions">Additional options</param>
        /// <param name="append"></param>
        /// <param name="cancellationToken"></param>
        /// <exception cref="ArgumentNullException">Output is null.</exception>
        /// <exception cref="ArgumentException">Output stream is not writeable</exception>
        public static async Task<ParquetWriter> CreateAsync(
            ParquetSchema schema, Stream output, ParquetOptions? formatOptions = null, bool append = false,
            CancellationToken cancellationToken = default) {
            var writer = new ParquetWriter(schema, output, formatOptions, append);
            await writer.PrepareFileAsync(append, cancellationToken);
            return writer;
        }

        /// <summary>
        /// Creates a new row group and a writer for it.
        /// </summary>
        public ParquetRowGroupWriter CreateRowGroup() {
            _dataWritten = true;

            var writer = new ParquetRowGroupWriter(_schema, Stream, _footer!,
               CompressionMethod, _formatOptions, CompressionLevel);

            _openedWriters.Add(writer);

            return writer;
        }

        /// <summary>
        /// Gets custom key-value pairs for metadata
        /// </summary>
        public IReadOnlyDictionary<string, string> CustomMetadata {
            get => _footer!.CustomMetadata;
            set => _footer!.CustomMetadata = value.ToDictionary(p => p.Key, p => p.Value);
        }

        private async Task PrepareFileAsync(bool append, CancellationToken cancellationToken) {
            if(append) {
                if(!Stream.CanSeek)
                    throw new IOException("destination stream must be seekable for append operations.");

                if(Stream.Length == 0)
                    throw new IOException($"you can only append to existing streams, but current stream is empty.");

                await ValidateFileAsync();

                FileMetaData fileMeta = await ReadMetadataAsync();
                _footer = new ThriftFooter(fileMeta);

                ValidateSchemasCompatible(_footer, _schema);

                await GoBeforeFooterAsync();
            } else {
                if(!string.IsNullOrWhiteSpace(_formatOptions.FooterEncryptionKey) && !_formatOptions.UsePlaintextFooter) {
                    byte[]? aadPrefixBytes = _formatOptions.AADPrefix is null
                        ? null
                        : System.Text.Encoding.ASCII.GetBytes(_formatOptions.AADPrefix);

                    if(_formatOptions.SupplyAadPrefix && aadPrefixBytes is null)
                        throw new ArgumentException("SupplyAadPrefix=true requires AADPrefix to be set.");

                    (_encrypter, _cryptoMeta) = EncryptionBase.CreateEncryptorForWrite(
                        _formatOptions.FooterEncryptionKey!,
                        aadPrefixBytes,
                        supplyAadPrefix: _formatOptions.SupplyAadPrefix,
                        useCtrVariant: _formatOptions.UseCtrVariant
                    );

                    this._encrypter = _encrypter ?? throw new InvalidOperationException("encrypter was not created");
                }
                if(_footer == null) {
                    _footer = new ThriftFooter(_schema, 0);
                    _footer.Encrypter = _encrypter;
                    // Head magic (PAR1 for plaintext mode, PARE for encrypted footer)
                    bool encryptedFooterMode = _encrypter != null && !_formatOptions.UsePlaintextFooter;
                    await WriteMagicAsync(encrypted: encryptedFooterMode);
                } else {
                    ValidateSchemasCompatible(_footer, _schema);
                    _footer.Add(0);
                }
                // Plaintext footer mode setup: advertise algorithm in FileMetaData and remember signer
                if(_formatOptions.UsePlaintextFooter && !string.IsNullOrWhiteSpace(_formatOptions.FooterSigningKey)) {
                    byte[]? aadPrefixBytes = _formatOptions.AADPrefix is null ? null : System.Text.Encoding.ASCII.GetBytes(_formatOptions.AADPrefix);
                    (EncryptionBase? encTmp, FileCryptoMetaData? cryptoMeta) = EncryptionBase.CreateEncryptorForWrite(
                        _formatOptions.FooterSigningKey!,
                        aadPrefixBytes,
                        supplyAadPrefix: _formatOptions.SupplyAadPrefix,
                        useCtrVariant: _formatOptions.UseCtrVariant
                    );
                    _plaintextAlg = cryptoMeta.EncryptionAlgorithm;
                    _signer = encTmp;             // keep for AAD building during signing
                    _footer.SetPlaintextFooterAlgorithm(_plaintextAlg);
                    // If you have metadata for the signing key, set it here:
                    // _footer.SetFooterSigningKeyMetadata(...);
                }
            }
        }

        private void ValidateSchemasCompatible(ThriftFooter footer, ParquetSchema schema) {
            ParquetSchema existingSchema = footer.CreateModelSchema(_formatOptions);

            if(!schema.Equals(existingSchema)) {
                string reason = schema.GetNotEqualsMessage(existingSchema, "appending", "existing");
                throw new ParquetException($"passed schema does not match existing file schema, reason: {reason}");
            }
        }

        private void WriteMagic(bool encrypted) => Stream.Write(encrypted ? MagicBytesEncrypted : MagicBytes, 0, MagicBytes.Length);
        private Task WriteMagicAsync(bool encrypted) => Stream.WriteAsync(encrypted ? MagicBytesEncrypted : MagicBytes, 0, MagicBytes.Length);

        private void DisposeCore() {
            if(_dataWritten) {
                //update row count (on append add row count to existing metadata)
                _footer!.Add(_openedWriters.Sum(w => w.RowCount ?? 0));
            }
        }

        /// <summary>
        /// Disposes the writer and writes the file footer.
        /// </summary>
        public void Dispose() {
            DisposeCore();
            if(_footer == null) {
                return;
            }

            using var ms = new MemoryStream();

            // --- Plaintext footer mode (always ends with PAR1) ---
            if(_formatOptions.UsePlaintextFooter) {
                _footer.Write(ms);
                byte[] footerBytes = ms.ToArray();

                if(_plaintextAlg is not null) {
                    // Signed plaintext footer (§5.5)
                    if(_signer is null)
                        throw new InvalidOperationException("Signer missing in plaintext footer mode.");

                    byte[] aad = _signer.BuildAad(Meta.ParquetModules.Footer);

                    byte[] nonce12 = new byte[12];
                    CryptoHelpers.FillNonce12(nonce12);

                    byte[] tag = new byte[16];
                    byte[] tmpCt = new byte[footerBytes.Length];

                    // Use the already parsed key on the signer
                    CryptoHelpers.GcmEncryptOrThrow(_signer.FooterEncryptionKey!, nonce12, footerBytes, tmpCt, tag, aad);

                    // [footer][nonce|tag][len=footer+28][PAR1]
                    Stream.Write(footerBytes, 0, footerBytes.Length);
                    Stream.Write(nonce12, 0, nonce12.Length);
                    Stream.Write(tag, 0, tag.Length);
                    Stream.WriteInt32(footerBytes.Length + 28);
                    WriteMagic(false);
                    Stream.Flush();
                    return;
                } else {
                    // Legacy plaintext footer (unsigned)
                    Stream.Write(footerBytes, 0, footerBytes.Length);
                    Stream.WriteInt32(footerBytes.Length);
                    WriteMagic(false);
                    Stream.Flush();
                    return;
                }
            }

            // --- Encrypted footer mode (PARE) ---
            if(_encrypter is not null) {
                _footer.Write(ms);
                byte[] encFooter = _encrypter.EncryptFooter(ms.ToArray());  // framed len|nonce|ct|tag

                using var metaMs = new MemoryStream();
                var metaWriter = new Parquet.Meta.Proto.ThriftCompactProtocolWriter(metaMs);
                _cryptoMeta!.Write(metaWriter);
                byte[] metaBytes = metaMs.ToArray();

                // [meta][encFooter][combinedLen][PARE]
                Stream.Write(metaBytes, 0, metaBytes.Length);
                Stream.Write(encFooter, 0, encFooter.Length);
                Stream.WriteInt32(metaBytes.Length + encFooter.Length);
                WriteMagic(true);
                Stream.Flush();
                return;
            }

            // --- Legacy plaintext footer (no encryption anywhere) ---
            _footer.Write(ms);
            byte[] footerPlain = ms.ToArray();
            Stream.Write(footerPlain, 0, footerPlain.Length);
            Stream.WriteInt32(footerPlain.Length);
            WriteMagic(false);
            Stream.Flush();
        }


        /// <summary>
        /// Dispose the writer asynchronously
        /// </summary>
        public async ValueTask DisposeAsync() {
            DisposeCore();
            if(_footer == null) {
                return;
            }

            using var ms = new MemoryStream();

            // --- Plaintext footer mode (always ends with PAR1) ---
            if(_formatOptions.UsePlaintextFooter) {
                await _footer.WriteAsync(ms).ConfigureAwait(false);
                byte[] footerBytes = ms.ToArray();

                if(_plaintextAlg is not null) {
                    // Signed plaintext footer (§5.5)
                    if(_signer is null)
                        throw new InvalidOperationException("Signer missing in plaintext footer mode.");

                    byte[] aad = _signer.BuildAad(Meta.ParquetModules.Footer);

                    byte[] nonce12 = new byte[12];
                    CryptoHelpers.FillNonce12(nonce12);

                    byte[] tag = new byte[16];
                    byte[] tmpCt = new byte[footerBytes.Length];

                    CryptoHelpers.GcmEncryptOrThrow(_signer.FooterEncryptionKey!, nonce12, footerBytes, tmpCt, tag, aad);

                    // [footer][nonce|tag][len=footer+28][PAR1]
                    await Stream.WriteAsync(footerBytes, 0, footerBytes.Length).ConfigureAwait(false);
                    await Stream.WriteAsync(nonce12, 0, nonce12.Length).ConfigureAwait(false);
                    await Stream.WriteAsync(tag, 0, tag.Length).ConfigureAwait(false);
                    await Stream.WriteInt32Async(footerBytes.Length + 28).ConfigureAwait(false);
                    await WriteMagicAsync(false).ConfigureAwait(false);
                    await Stream.FlushAsync().ConfigureAwait(false);
                    return;
                } else {
                    // Legacy plaintext footer (unsigned)
                    await Stream.WriteAsync(footerBytes, 0, footerBytes.Length).ConfigureAwait(false);
                    await Stream.WriteInt32Async(footerBytes.Length).ConfigureAwait(false);
                    await WriteMagicAsync(false).ConfigureAwait(false);
                    await Stream.FlushAsync().ConfigureAwait(false);
                    return;
                }
            }

            // --- Encrypted footer mode (PARE) ---
            if(_encrypter is not null) {
                ms.SetLength(0);
                await _footer.WriteAsync(ms).ConfigureAwait(false);
                byte[] encFooter = _encrypter.EncryptFooter(ms.ToArray()); // framed len|nonce|ct|tag

                using var metaMs = new MemoryStream();
                var metaWriter = new Parquet.Meta.Proto.ThriftCompactProtocolWriter(metaMs);
                _cryptoMeta!.Write(metaWriter);
                byte[] metaBytes = metaMs.ToArray();

                // [meta][encFooter][combinedLen][PARE]
                await Stream.WriteAsync(metaBytes, 0, metaBytes.Length).ConfigureAwait(false);
                await Stream.WriteAsync(encFooter, 0, encFooter.Length).ConfigureAwait(false);
                await Stream.WriteInt32Async(metaBytes.Length + encFooter.Length).ConfigureAwait(false);
                await WriteMagicAsync(true).ConfigureAwait(false);
                await Stream.FlushAsync().ConfigureAwait(false);
                return;
            }

            // --- Legacy plaintext footer (no encryption anywhere) ---
            ms.SetLength(0);
            await _footer.WriteAsync(ms).ConfigureAwait(false);
            byte[] footerPlain = ms.ToArray();
            await Stream.WriteAsync(footerPlain, 0, footerPlain.Length).ConfigureAwait(false);
            await Stream.WriteInt32Async(footerPlain.Length).ConfigureAwait(false);
            await WriteMagicAsync(false).ConfigureAwait(false);
            await Stream.FlushAsync().ConfigureAwait(false);
        }
    }
}
